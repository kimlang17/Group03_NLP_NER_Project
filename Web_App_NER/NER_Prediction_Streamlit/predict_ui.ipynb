{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\CADT\\Data science\\Year 4\\NLP\\NLP_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# Path to the saved model directory\n",
    "output_dir = r\"C:\\CADT\\Data science\\Year 4\\NLPner_model\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "model = AutoModelForTokenClassification.from_pretrained(output_dir)\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully!\n",
      "Named Entity Recognition (NER) Prediction Interface\n",
      "Type 'exit' to quit.\n",
      "\n",
      "Predicted NER Labels:\n",
      "produces: O\n",
      "natural: B\n",
      "written: I\n",
      "or: O\n",
      "spoken: I\n",
      "language: I\n",
      "from: O\n",
      "structured: B\n",
      "and: O\n",
      "un: B\n",
      "##st: B\n",
      "##ructured: B\n",
      "data: I\n",
      "\n",
      "Predicted NER Labels:\n",
      "produces: O\n",
      "natural: B\n",
      "written: I\n",
      "or: O\n",
      "spoken: I\n",
      "language: I\n",
      "from: O\n",
      "structured: B\n",
      "and: O\n",
      "un: B\n",
      "##st: B\n",
      "##ructured: B\n",
      "data: I\n",
      "\n",
      "Predicted NER Labels:\n",
      "this: O\n",
      "blog: O\n",
      "discusses: O\n",
      "the: O\n",
      "different: O\n",
      "nl: B\n",
      "##p: B\n",
      "techniques: O\n",
      "and: O\n",
      "tasks: O\n",
      ".: O\n",
      "we: O\n",
      "will: O\n",
      "be: O\n",
      "using: O\n",
      "python: B\n",
      "code: I\n",
      "to: O\n",
      "demo: O\n",
      "what: O\n",
      "and: O\n",
      "how: O\n",
      "each: O\n",
      "task: O\n",
      "works: O\n",
      ".: O\n",
      "\n",
      "Predicted NER Labels:\n",
      "\n",
      "Predicted NER Labels:\n",
      "\n",
      "Predicted NER Labels:\n",
      "\n",
      "Predicted NER Labels:\n",
      "\n",
      "Predicted NER Labels:\n",
      "\n",
      "Predicted NER Labels:\n",
      "\n",
      "Predicted NER Labels:\n",
      "\n",
      "Predicted NER Labels:\n",
      "\n",
      "Predicted NER Labels:\n",
      "\n",
      "Predicted NER Labels:\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# Load the saved model and tokenizer\n",
    "def load_model(output_dir):\n",
    "    \"\"\"\n",
    "    Loads the model and tokenizer from the specified directory.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(output_dir)\n",
    "    return model, tokenizer\n",
    "\n",
    "# Perform NER predictions\n",
    "def predict_ner(text, model, tokenizer, id2label):\n",
    "    \"\"\"\n",
    "    Performs NER on the given text using the trained model.\n",
    "    Args:\n",
    "        text (str): The input text for NER.\n",
    "        model: The trained NER model.\n",
    "        tokenizer: Tokenizer corresponding to the model.\n",
    "        id2label (dict): Mapping of label IDs to label names.\n",
    "\n",
    "    Returns:\n",
    "        List of tuples: Each tuple contains a token and its predicted label.\n",
    "    \"\"\"\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    \n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Process outputs\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=2).squeeze().tolist()\n",
    "    \n",
    "    # Map tokens to labels\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze().tolist())\n",
    "    labels = [id2label[pred] for pred in predictions]\n",
    "\n",
    "    # Exclude special tokens ([CLS], [SEP])\n",
    "    predictions_with_labels = [\n",
    "        (token, label) for token, label in zip(tokens, labels) \n",
    "        if token not in tokenizer.all_special_tokens\n",
    "    ]\n",
    "    return predictions_with_labels\n",
    "\n",
    "# Command-line interface for NER\n",
    "def ner_prediction_interface(model, tokenizer, id2label):\n",
    "    \"\"\"\n",
    "    Provides a CLI interface for inputting sentences and predicting NER labels.\n",
    "    Args:\n",
    "        model: The trained NER model.\n",
    "        tokenizer: Tokenizer corresponding to the model.\n",
    "        id2label (dict): Mapping of label IDs to label names.\n",
    "    \"\"\"\n",
    "    print(\"Named Entity Recognition (NER) Prediction Interface\")\n",
    "    print(\"Type 'exit' to quit.\")\n",
    "    \n",
    "    while True:\n",
    "        # Input sentence\n",
    "        text = input(\"\\nEnter a sentence for NER prediction: \")\n",
    "        if text.lower() == \"exit\":\n",
    "            print(\"Exiting... Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Perform predictions\n",
    "        predictions = predict_ner(text, model, tokenizer, id2label)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\nPredicted NER Labels:\")\n",
    "        for token, label in predictions:\n",
    "            print(f\"{token}: {label}\")\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to your saved model\n",
    "    # output_dir = \"./ner_model\"\n",
    "    output_dir = r\"C:\\CADT\\Data science\\Year 4\\NLPner_model\"\n",
    "\n",
    "    # Define label mapping (Replace with actual labels)\n",
    "    id2label = {0: \"O\", 1: \"B\", 2: \"I\"}  # Update with your label mapping\n",
    "    \n",
    "    # Load the model and tokenizer\n",
    "    model, tokenizer = load_model(output_dir)\n",
    "    print(\"Model and tokenizer loaded successfully!\")\n",
    "\n",
    "    # Launch the prediction interface\n",
    "    ner_prediction_interface(model, tokenizer, id2label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from streamlit) (2.0.2)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Collecting protobuf<6,>=3.20 (from streamlit)\n",
      "  Downloading protobuf-5.29.1-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-18.1.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from streamlit) (13.9.4)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-1.18.4-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: colorama in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.22.3-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\cadt\\data science\\year 4\\nlp\\nlp_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
      "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/9.1 MB 1.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.0/9.1 MB 1.6 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.6/9.1 MB 1.8 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.1/9.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 2.6/9.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.1/9.1 MB 2.1 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 3.9/9.1 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 4.5/9.1 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.7/9.1 MB 2.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.2/9.1 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.8/9.1 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.8/9.1 MB 2.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.3/9.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.8/9.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.8/9.1 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.3/9.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.9/9.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.9/9.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.4/9.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.9/9.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.1/9.1 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 262.1/731.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 731.2/731.2 kB 2.5 MB/s eta 0:00:00\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Downloading protobuf-5.29.1-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading pyarrow-18.1.0-cp311-cp311-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/25.1 MB 3.4 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.0/25.1 MB 2.5 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/25.1 MB 2.7 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 1.8/25.1 MB 2.1 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 2.1/25.1 MB 2.0 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 2.6/25.1 MB 2.1 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 3.1/25.1 MB 2.1 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 3.7/25.1 MB 2.2 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 3.9/25.1 MB 2.1 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 4.5/25.1 MB 2.1 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 4.7/25.1 MB 2.0 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 5.0/25.1 MB 1.9 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 5.5/25.1 MB 2.0 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 6.0/25.1 MB 2.1 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 6.6/25.1 MB 2.1 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 7.1/25.1 MB 2.1 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 7.6/25.1 MB 2.1 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 8.1/25.1 MB 2.1 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 8.4/25.1 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 8.9/25.1 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 9.2/25.1 MB 2.1 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 9.7/25.1 MB 2.1 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 10.2/25.1 MB 2.1 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 11.0/25.1 MB 2.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 11.5/25.1 MB 2.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 12.6/25.1 MB 2.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 13.4/25.1 MB 2.3 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 13.9/25.1 MB 2.4 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 14.4/25.1 MB 2.4 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 14.9/25.1 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 15.5/25.1 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 15.7/25.1 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 16.0/25.1 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 16.5/25.1 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 17.0/25.1 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 17.0/25.1 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 17.6/25.1 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 18.1/25.1 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 18.4/25.1 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 18.6/25.1 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 19.1/25.1 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 19.9/25.1 MB 2.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 20.7/25.1 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 21.2/25.1 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.8/25.1 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 22.5/25.1 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 23.1/25.1 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.3/25.1 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.9/25.1 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.4/25.1 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.9/25.1 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.8/6.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.3/6.9 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.8/6.9 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.4/6.9 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.9/6.9 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.4/6.9 MB 2.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.9/6.9 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 4.5/6.9 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.7/6.9 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.2/6.9 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.8/6.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.3/6.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading narwhals-1.18.4-py3-none-any.whl (251 kB)\n",
      "Downloading attrs-24.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.22.3-cp311-cp311-win_amd64.whl (231 kB)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: watchdog, toml, tenacity, smmap, rpds-py, pyarrow, protobuf, narwhals, cachetools, blinker, attrs, referencing, pydeck, gitdb, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "Successfully installed altair-5.5.0 attrs-24.3.0 blinker-1.9.0 cachetools-5.5.0 gitdb-4.0.11 gitpython-3.1.43 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 narwhals-1.18.4 protobuf-5.29.1 pyarrow-18.1.0 pydeck-0.9.1 referencing-0.35.1 rpds-py-0.22.3 smmap-5.0.1 streamlit-1.41.1 tenacity-9.0.0 toml-0.10.2 watchdog-6.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 14:58:56.788 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 14:58:56.789 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 14:58:56.920 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\CADT\\Data science\\Year 4\\NLP\\NLP_env\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-12-16 14:58:56.921 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 14:58:56.922 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 14:58:56.923 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 14:58:56.924 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 14:58:56.924 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 14:58:56.925 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 14:58:56.926 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 14:58:56.927 Session state does not function when running a script without `streamlit run`\n",
      "2024-12-16 14:58:56.928 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 14:58:56.928 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 14:58:56.929 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 14:58:56.930 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 14:58:56.931 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 14:58:56.931 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 14:58:56.931 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 14:58:56.932 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 14:58:56.932 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# Path to the saved model and tokenizer\n",
    "output_dir = r\"NLPner_model\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "model = AutoModelForTokenClassification.from_pretrained(output_dir)\n",
    "\n",
    "# Define your id2label mapping (adjust based on your model's labels)\n",
    "id2label = {0: \"O\", 1: \"B\", 2: \"I\"}  # Adjust to match your model's label IDs\n",
    "\n",
    "# Function to predict NER labels\n",
    "def predict_ner(text, model, tokenizer, id2label):\n",
    "    \"\"\"\n",
    "    Predicts NER labels for the input text using the model and tokenizer.\n",
    "    \"\"\"\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get predicted labels\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=2).squeeze().tolist()\n",
    "\n",
    "    # Convert token IDs to tokens\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze().tolist())\n",
    "\n",
    "    # Map predictions to labels\n",
    "    labels = [id2label[pred] for pred in predictions]\n",
    "\n",
    "    # Filter out special tokens\n",
    "    predictions_with_labels = [\n",
    "        (token, label) for token, label in zip(tokens, labels) if token not in tokenizer.all_special_tokens\n",
    "    ]\n",
    "    \n",
    "    return predictions_with_labels\n",
    "\n",
    "# Streamlit Interface\n",
    "def run_streamlit_interface():\n",
    "    # Set page configuration\n",
    "    st.set_page_config(page_title=\"NER Prediction\", layout=\"wide\")\n",
    "    \n",
    "    # Add a custom header and subtitle\n",
    "    st.markdown(\"<h1 style='text-align: center; color: #4CAF50;'>Named Entity Recognition (NER)</h1>\", unsafe_allow_html=True)\n",
    "    st.markdown(\"<h3 style='text-align: center;'>Predict entity labels from a given sentence</h3>\", unsafe_allow_html=True)\n",
    "\n",
    "    # Styled input box for the sentence\n",
    "    text = st.text_area(\n",
    "        \"Enter a Sentence for NER Prediction:\",\n",
    "        placeholder=\"Type your sentence here...\",\n",
    "        height=150,\n",
    "        max_chars=500,\n",
    "        help=\"Enter a sentence, and the model will predict the named entities in it.\"\n",
    "    )\n",
    "\n",
    "    # Apply some styling to buttons\n",
    "    button_style = \"\"\"\n",
    "    <style>\n",
    "        .stButton>button {\n",
    "            background-color: #4CAF50;\n",
    "            color: white;\n",
    "            border-radius: 10px;\n",
    "            padding: 10px 30px;\n",
    "            font-size: 16px;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    st.markdown(button_style, unsafe_allow_html=True)\n",
    "\n",
    "    # Create a custom button to trigger the prediction\n",
    "    if st.button(\"Predict NER\"):\n",
    "        if text.strip():  # Check if the text is not empty\n",
    "            with st.spinner('Predicting...'):\n",
    "                # Get predictions\n",
    "                predictions = predict_ner(text, model, tokenizer, id2label)\n",
    "\n",
    "                # Display the predictions in a nicely formatted list\n",
    "                st.subheader(\"Prediction Results:\")\n",
    "                st.markdown(\"<h4 style='text-align: center;'>Entities Detected:</h4>\", unsafe_allow_html=True)\n",
    "                \n",
    "                # Using a simple list format for displaying predictions\n",
    "                for token, label in predictions:\n",
    "                    st.markdown(f\"<b>{token}</b>: {label}\", unsafe_allow_html=True)\n",
    "        else:\n",
    "            st.warning(\"Please enter a sentence to predict.\")\n",
    "\n",
    "# Run the Streamlit app\n",
    "if __name__ == \"__main__\":\n",
    "    run_streamlit_interface()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
