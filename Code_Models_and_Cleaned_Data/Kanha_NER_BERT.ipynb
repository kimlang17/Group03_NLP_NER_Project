{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c7b8070579c4401d9b31aecb14dadb98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7e477ff3f3347a794499a51d3c6de73",
              "IPY_MODEL_aa0df0cae7bc4f5f897ea736e756394a",
              "IPY_MODEL_0125bfb141894e8ebc0a317a54f8ad04"
            ],
            "layout": "IPY_MODEL_292124b290994c0198c9f2f325ff58e2"
          }
        },
        "b7e477ff3f3347a794499a51d3c6de73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7609da18b4d4d049306cd22c5328cba",
            "placeholder": "​",
            "style": "IPY_MODEL_1aa57990e94f476e9d9a5cf37d383f1d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "aa0df0cae7bc4f5f897ea736e756394a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0e8f6784def4841bac5c4b63cabbb8e",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54c20be7aa874b2f98cad4a05a5594fb",
            "value": 48
          }
        },
        "0125bfb141894e8ebc0a317a54f8ad04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5523b34b35e45a89a5f7673f979bb9e",
            "placeholder": "​",
            "style": "IPY_MODEL_0cd5594e29b349518fc674801a154c4a",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.59kB/s]"
          }
        },
        "292124b290994c0198c9f2f325ff58e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7609da18b4d4d049306cd22c5328cba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aa57990e94f476e9d9a5cf37d383f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0e8f6784def4841bac5c4b63cabbb8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54c20be7aa874b2f98cad4a05a5594fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5523b34b35e45a89a5f7673f979bb9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cd5594e29b349518fc674801a154c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc63b54472124904a4011238bfdb7337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e851caa894f41dc9d7dfb8b05bdb69d",
              "IPY_MODEL_479e630e89ee4538bd7546ba0523a958",
              "IPY_MODEL_54bd2bef91804f329353a4967fbe222e"
            ],
            "layout": "IPY_MODEL_9bf37d58b0e142b1b2929fa2642dbe2d"
          }
        },
        "4e851caa894f41dc9d7dfb8b05bdb69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adfd1d40ee064cd789dacd13a592023a",
            "placeholder": "​",
            "style": "IPY_MODEL_990585b297e3474aa188b1e3a7f28511",
            "value": "vocab.txt: 100%"
          }
        },
        "479e630e89ee4538bd7546ba0523a958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dac3c478ae946559c85b6855da84b39",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bff0f5b75f3476288e442aeac6950c0",
            "value": 231508
          }
        },
        "54bd2bef91804f329353a4967fbe222e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a04f9fcea3a5448786297566a639088f",
            "placeholder": "​",
            "style": "IPY_MODEL_6ff23da6610a49398caeb443dd9d29e1",
            "value": " 232k/232k [00:00&lt;00:00, 505kB/s]"
          }
        },
        "9bf37d58b0e142b1b2929fa2642dbe2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adfd1d40ee064cd789dacd13a592023a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "990585b297e3474aa188b1e3a7f28511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dac3c478ae946559c85b6855da84b39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bff0f5b75f3476288e442aeac6950c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a04f9fcea3a5448786297566a639088f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff23da6610a49398caeb443dd9d29e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a41c5518123a479795f73dc4455765e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2ce0c99889b42d0bc2b0cbd48e626fb",
              "IPY_MODEL_299a6c285f7b4b8383f1a20170ab5934",
              "IPY_MODEL_618646db87704eaeb73a1e1d40e3b92b"
            ],
            "layout": "IPY_MODEL_40428549fc3b456b8f153af38f81bc63"
          }
        },
        "c2ce0c99889b42d0bc2b0cbd48e626fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c0f7a5b78eb4326ae875ee29ea835be",
            "placeholder": "​",
            "style": "IPY_MODEL_c4f13768630a4bd39df6422eeca71a16",
            "value": "tokenizer.json: 100%"
          }
        },
        "299a6c285f7b4b8383f1a20170ab5934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52968ed022764181914ce0f1bb0d95bb",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_654981ee5bf9402ebe76aeb92c661ccd",
            "value": 466062
          }
        },
        "618646db87704eaeb73a1e1d40e3b92b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f967ba690134dd1ac42029554767e3b",
            "placeholder": "​",
            "style": "IPY_MODEL_e694a449fc1a462cb6f396bb6f6cb578",
            "value": " 466k/466k [00:00&lt;00:00, 531kB/s]"
          }
        },
        "40428549fc3b456b8f153af38f81bc63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c0f7a5b78eb4326ae875ee29ea835be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4f13768630a4bd39df6422eeca71a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52968ed022764181914ce0f1bb0d95bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "654981ee5bf9402ebe76aeb92c661ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f967ba690134dd1ac42029554767e3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e694a449fc1a462cb6f396bb6f6cb578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97704bbf23f0436093211c1615296041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61e43daa5ea542ddb1d594a4e9050229",
              "IPY_MODEL_8a2a697ab62d438da987b24518134c3d",
              "IPY_MODEL_40c4808715684fbdbc4816acf9445520"
            ],
            "layout": "IPY_MODEL_8b0fbacb768b4ef3b2d70f6099dd06b5"
          }
        },
        "61e43daa5ea542ddb1d594a4e9050229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9d2affc8b184911bc8b9cc40b8f30b5",
            "placeholder": "​",
            "style": "IPY_MODEL_183e78fae57e4f4cb9b88e1d45efe0b4",
            "value": "config.json: 100%"
          }
        },
        "8a2a697ab62d438da987b24518134c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c03d1dbdf56749c285a1c5aa536ea871",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28ada5baa9c74a60bddbede1774e8f4e",
            "value": 570
          }
        },
        "40c4808715684fbdbc4816acf9445520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff3380082a7c48bc841643a73ada75b8",
            "placeholder": "​",
            "style": "IPY_MODEL_3e3eb11c723549b0bd5a8c23069a5b4f",
            "value": " 570/570 [00:00&lt;00:00, 44.1kB/s]"
          }
        },
        "8b0fbacb768b4ef3b2d70f6099dd06b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9d2affc8b184911bc8b9cc40b8f30b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "183e78fae57e4f4cb9b88e1d45efe0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c03d1dbdf56749c285a1c5aa536ea871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28ada5baa9c74a60bddbede1774e8f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff3380082a7c48bc841643a73ada75b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e3eb11c723549b0bd5a8c23069a5b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10644bf16b1d464f97ec475d46700dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4225b5059424dba8a5df1a88c4db42b",
              "IPY_MODEL_baf474c14bcc435092fc3d3bad4b3ed4",
              "IPY_MODEL_5f755454b5234f1481d0bf044e07f636"
            ],
            "layout": "IPY_MODEL_d6d18eaf51e04664aca3053e598d8ccf"
          }
        },
        "c4225b5059424dba8a5df1a88c4db42b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec5a088e74ce44b8bdcddef5666f5d6a",
            "placeholder": "​",
            "style": "IPY_MODEL_141c94e3e0fb4b71975f146f126d2ef5",
            "value": "model.safetensors: 100%"
          }
        },
        "baf474c14bcc435092fc3d3bad4b3ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c93d55a432864231abc07afc30a96fdd",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37e165b96a744b19883d39f77f336ebd",
            "value": 440449768
          }
        },
        "5f755454b5234f1481d0bf044e07f636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39b9ddfdd05347e8af7c48340d8a7118",
            "placeholder": "​",
            "style": "IPY_MODEL_0cbe1a0e2d9d486099b1c299ed0a1b40",
            "value": " 440M/440M [00:04&lt;00:00, 130MB/s]"
          }
        },
        "d6d18eaf51e04664aca3053e598d8ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec5a088e74ce44b8bdcddef5666f5d6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "141c94e3e0fb4b71975f146f126d2ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c93d55a432864231abc07afc30a96fdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37e165b96a744b19883d39f77f336ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39b9ddfdd05347e8af7c48340d8a7118": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cbe1a0e2d9d486099b1c299ed0a1b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gwbukmmQ-69Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Load the data\n",
        "train_data = pd.read_csv(r\"data_train.csv\")\n",
        "dev_data = pd.read_csv(r\"data_dev.csv\")\n",
        "test_data = pd.read_csv(r\"data_test.csv\")"
      ],
      "metadata": {
        "id": "7xAipiyCCcgX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def calculate_average_length(file_path):\n",
        "    # Load the data\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    # Ensure columns are present\n",
        "    assert 'token' in data.columns, \"The file must contain a 'token' column.\"\n",
        "    assert 'label' in data.columns, \"The file must contain a 'label' column.\"\n",
        "\n",
        "    # List to store sentence lengths\n",
        "    sentence_lengths = []\n",
        "    current_sentence = []\n",
        "\n",
        "    # Sentence-ending punctuation\n",
        "    sentence_endings = [\".\", \"!\", \"?\"]\n",
        "\n",
        "    for token in data['token']:\n",
        "        current_sentence.append(token)\n",
        "        if token in sentence_endings:\n",
        "            sentence_lengths.append(len(current_sentence))  # Add sentence length\n",
        "            current_sentence = []  # Start a new sentence\n",
        "\n",
        "    # If there's a trailing sentence without an ending punctuation\n",
        "    if current_sentence:\n",
        "        sentence_lengths.append(len(current_sentence))\n",
        "\n",
        "    # Calculate the average length\n",
        "    average_length = sum(sentence_lengths) / len(sentence_lengths) if sentence_lengths else 0\n",
        "    return average_length\n",
        "\n",
        "# Paths to the CSV files\n",
        "train_file = \"data_train.csv\"\n",
        "dev_file = \"data_dev.csv\"\n",
        "test_file = \"data_test.csv\"\n",
        "\n",
        "# Calculate average lengths\n",
        "train_avg_length = calculate_average_length(train_file)\n",
        "dev_avg_length = calculate_average_length(dev_file)\n",
        "test_avg_length = calculate_average_length(test_file)\n",
        "\n",
        "print(f\"Average sentence length in train.csv: {train_avg_length:.2f} tokens\")\n",
        "print(f\"Average sentence length in dev.csv: {dev_avg_length:.2f} tokens\")\n",
        "print(f\"Average sentence length in test.csv: {test_avg_length:.2f} tokens\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9R6VuMDC9lh",
        "outputId": "810931b5-4c55-4f6b-ebbb-48ac59d7cb00"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average sentence length in train.csv: 28.66 tokens\n",
            "Average sentence length in dev.csv: 27.90 tokens\n",
            "Average sentence length in test.csv: 28.88 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def prepare_data_with_token_limit(df, max_tokens):\n",
        "    \"\"\"\n",
        "    Groups tokens and labels into sentences with a maximum token limit,\n",
        "    ensuring no sentence ends with an incomplete entity, and assigns a unique ID to each sequence.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Dataframe with columns 'token' and 'label'.\n",
        "        max_tokens (int): Maximum number of tokens allowed in a sentence.\n",
        "\n",
        "    Returns:\n",
        "        sequences (list of dict): List of dictionaries containing 'id', 'tokens', and 'labels'.\n",
        "    \"\"\"\n",
        "    sequences = []\n",
        "    current_tokens = []\n",
        "    current_labels = []\n",
        "    sequence_id = 0\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        token, label = row[\"token\"], row[\"label\"]\n",
        "\n",
        "        # Add token and label to the current sequence\n",
        "        current_tokens.append(token)\n",
        "        current_labels.append(label)\n",
        "\n",
        "        # Check if we reached the max token limit\n",
        "        if len(current_tokens) >= max_tokens:\n",
        "            # Save the current sequence with its ID\n",
        "            sequences.append({\n",
        "                \"id\": str(sequence_id),\n",
        "                \"tokens\": current_tokens,\n",
        "                \"labels\": current_labels\n",
        "            })\n",
        "            sequence_id += 1\n",
        "            current_tokens = []\n",
        "            current_labels = []\n",
        "\n",
        "    # Add the last sequence if present\n",
        "    if current_tokens:\n",
        "        sequences.append({\n",
        "            \"id\": str(sequence_id),\n",
        "            \"tokens\": current_tokens,\n",
        "            \"labels\": current_labels\n",
        "        })\n",
        "\n",
        "    return sequences\n",
        "\n",
        "# Example usage\n",
        "train_data = pd.read_csv(\"data_train.csv\")  # Your dataset\n",
        "max_tokens = 30  # Define your max token limit\n",
        "train_sequences = prepare_data_with_token_limit(train_data, max_tokens)\n",
        "\n",
        "# Display the first sequence\n",
        "print(train_sequences[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQTG0OOQDKd5",
        "outputId": "01825c63-928b-4353-fe87-9e7fb97c6805"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '0', 'tokens': ['In', 'this', 'article', 'we', 'discuss', 'several', 'metrics', 'of', 'coherence', 'defined', 'using', 'centering', 'theory', 'and', 'investigate', 'the', 'usefulness', 'of', 'such', 'metrics', 'for', 'information', 'ordering', 'in', 'automatic', 'text', 'generation', '.', 'We', 'estimate'], 'labels': ['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_sentences = prepare_data_with_token_limit(dev_data, max_tokens)\n",
        "test_sentences = prepare_data_with_token_limit(test_data, max_tokens)\n",
        "\n"
      ],
      "metadata": {
        "id": "4y7nvMBjDT2X"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwAAShQyVTZ4",
        "outputId": "e539260b-8da7-4c7f-93dc-bb5ec59676e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['This',\n",
              "  'article',\n",
              "  'presents',\n",
              "  'an',\n",
              "  'investigation',\n",
              "  'of',\n",
              "  'corpus',\n",
              "  'based',\n",
              "  'methods',\n",
              "  'for',\n",
              "  'the',\n",
              "  'automation',\n",
              "  'of',\n",
              "  'help',\n",
              "  'desk',\n",
              "  'e',\n",
              "  'mail',\n",
              "  'responses',\n",
              "  '.',\n",
              "  'Specifically',\n",
              "  ',',\n",
              "  'we',\n",
              "  'investigate',\n",
              "  'this',\n",
              "  'problem',\n",
              "  'along',\n",
              "  'two',\n",
              "  'operational',\n",
              "  'dimensions',\n",
              "  ':'],\n",
              " 'labels': ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B',\n",
              "  'I',\n",
              "  'O']}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMteKREMDaAu",
        "outputId": "f869c8a0-f699-453c-ac39-9c778fea8de4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['In',\n",
              "  'this',\n",
              "  'article',\n",
              "  'we',\n",
              "  'discuss',\n",
              "  'several',\n",
              "  'metrics',\n",
              "  'of',\n",
              "  'coherence',\n",
              "  'defined',\n",
              "  'using',\n",
              "  'centering',\n",
              "  'theory',\n",
              "  'and',\n",
              "  'investigate',\n",
              "  'the',\n",
              "  'usefulness',\n",
              "  'of',\n",
              "  'such',\n",
              "  'metrics',\n",
              "  'for',\n",
              "  'information',\n",
              "  'ordering',\n",
              "  'in',\n",
              "  'automatic',\n",
              "  'text',\n",
              "  'generation',\n",
              "  '.',\n",
              "  'We',\n",
              "  'estimate'],\n",
              " 'labels': ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B',\n",
              "  'I',\n",
              "  'I',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B',\n",
              "  'I',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B',\n",
              "  'I',\n",
              "  'I',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O']}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers import DataCollatorForTokenClassification  # This libary apply augumentation technique at runtime\n",
        "from transformers import AutoModelForTokenClassification     # This class is responsible for load model into my memory\n",
        ""
      ],
      "metadata": {
        "id": "IoRkhF5oFP3R"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## tokenizer\n",
        "# intializing tokenizer with help of bert model\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274,
          "referenced_widgets": [
            "c7b8070579c4401d9b31aecb14dadb98",
            "b7e477ff3f3347a794499a51d3c6de73",
            "aa0df0cae7bc4f5f897ea736e756394a",
            "0125bfb141894e8ebc0a317a54f8ad04",
            "292124b290994c0198c9f2f325ff58e2",
            "c7609da18b4d4d049306cd22c5328cba",
            "1aa57990e94f476e9d9a5cf37d383f1d",
            "c0e8f6784def4841bac5c4b63cabbb8e",
            "54c20be7aa874b2f98cad4a05a5594fb",
            "f5523b34b35e45a89a5f7673f979bb9e",
            "0cd5594e29b349518fc674801a154c4a",
            "fc63b54472124904a4011238bfdb7337",
            "4e851caa894f41dc9d7dfb8b05bdb69d",
            "479e630e89ee4538bd7546ba0523a958",
            "54bd2bef91804f329353a4967fbe222e",
            "9bf37d58b0e142b1b2929fa2642dbe2d",
            "adfd1d40ee064cd789dacd13a592023a",
            "990585b297e3474aa188b1e3a7f28511",
            "4dac3c478ae946559c85b6855da84b39",
            "3bff0f5b75f3476288e442aeac6950c0",
            "a04f9fcea3a5448786297566a639088f",
            "6ff23da6610a49398caeb443dd9d29e1",
            "a41c5518123a479795f73dc4455765e4",
            "c2ce0c99889b42d0bc2b0cbd48e626fb",
            "299a6c285f7b4b8383f1a20170ab5934",
            "618646db87704eaeb73a1e1d40e3b92b",
            "40428549fc3b456b8f153af38f81bc63",
            "9c0f7a5b78eb4326ae875ee29ea835be",
            "c4f13768630a4bd39df6422eeca71a16",
            "52968ed022764181914ce0f1bb0d95bb",
            "654981ee5bf9402ebe76aeb92c661ccd",
            "6f967ba690134dd1ac42029554767e3b",
            "e694a449fc1a462cb6f396bb6f6cb578",
            "97704bbf23f0436093211c1615296041",
            "61e43daa5ea542ddb1d594a4e9050229",
            "8a2a697ab62d438da987b24518134c3d",
            "40c4808715684fbdbc4816acf9445520",
            "8b0fbacb768b4ef3b2d70f6099dd06b5",
            "d9d2affc8b184911bc8b9cc40b8f30b5",
            "183e78fae57e4f4cb9b88e1d45efe0b4",
            "c03d1dbdf56749c285a1c5aa536ea871",
            "28ada5baa9c74a60bddbede1774e8f4e",
            "ff3380082a7c48bc841643a73ada75b8",
            "3e3eb11c723549b0bd5a8c23069a5b4f"
          ]
        },
        "id": "LwRYQs6KEszz",
        "outputId": "77cb402f-96ab-4d51-e4f8-a5120675bda2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7b8070579c4401d9b31aecb14dadb98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc63b54472124904a4011238bfdb7337"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a41c5518123a479795f73dc4455765e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97704bbf23f0436093211c1615296041"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUm_-75SFLbJ",
        "outputId": "2d762009-ee6f-4d72-f72f-a474003028bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = train_sequences[0]\n",
        "\n",
        "# Tokenize the input text\n",
        "tokenized_input = tokenizer(example_text['tokens'], is_split_into_words=True)\n",
        "\n",
        "# Convert token IDs to tokens\n",
        "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
        "\n",
        "# Get the word IDs that map each token to its original word\n",
        "word_ids = tokenized_input.word_ids()\n"
      ],
      "metadata": {
        "id": "8Q_iUytDFYou"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_input)\n",
        "print(\"\\n\")\n",
        "print(tokens)\n",
        "print(\"\\n\")\n",
        "print(word_ids)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5PekSHfFkhY",
        "outputId": "f8465044-294a-41e7-e11f-6fc6d8119ee7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 1999, 2023, 3720, 2057, 6848, 2195, 12046, 2015, 1997, 2522, 5886, 10127, 4225, 2478, 2415, 2075, 3399, 1998, 8556, 1996, 6179, 2791, 1997, 2107, 12046, 2015, 2005, 2592, 13063, 1999, 6882, 3793, 4245, 1012, 2057, 10197, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "\n",
            "\n",
            "['[CLS]', 'in', 'this', 'article', 'we', 'discuss', 'several', 'metric', '##s', 'of', 'co', '##her', '##ence', 'defined', 'using', 'center', '##ing', 'theory', 'and', 'investigate', 'the', 'useful', '##ness', 'of', 'such', 'metric', '##s', 'for', 'information', 'ordering', 'in', 'automatic', 'text', 'generation', '.', 'we', 'estimate', '[SEP]']\n",
            "\n",
            "\n",
            "[None, 0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 8, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Length of the tokens is : {len(tokens)}')\n",
        "print(f'Length of the ner tags is: {len(train_sequences[0][\"labels\"])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAb4Ke-bFwU-",
        "outputId": "1625274a-5930-46a7-a3a2-735281893b3f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the tokens is : 38\n",
            "Length of the ner tags is: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
        "    tokenized_inputs = {\n",
        "        \"input_ids\": [],\n",
        "        \"attention_mask\": [],\n",
        "        \"labels\": []\n",
        "    }\n",
        "\n",
        "    for example in examples:  # Iterate over list of dictionaries\n",
        "        tokenized = tokenizer(\n",
        "        example[\"tokens\"],\n",
        "        truncation=True,  # Apply truncation\n",
        "        padding='max_length',  # Apply padding\n",
        "        max_length=30,  # Set max length\n",
        "        is_split_into_words=True\n",
        "    )\n",
        "        labels = []\n",
        "        word_ids = tokenized.word_ids()\n",
        "\n",
        "        for i, word_id in enumerate(word_ids):\n",
        "            if word_id is None:\n",
        "                labels.append(-100)\n",
        "            else:\n",
        "                label = example[\"labels\"][word_id]\n",
        "                if label_all_tokens:\n",
        "                    labels.append(label)\n",
        "                else:\n",
        "                    labels.append(label if i == 0 else -100)\n",
        "\n",
        "        tokenized_inputs[\"input_ids\"].append(tokenized[\"input_ids\"])\n",
        "        tokenized_inputs[\"attention_mask\"].append(tokenized[\"attention_mask\"])\n",
        "        tokenized_inputs[\"labels\"].append(labels)\n",
        "\n",
        "    return tokenized_inputs\n"
      ],
      "metadata": {
        "id": "yEP4LLW5F_EF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences[4:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgeSu9CxHkOa",
        "outputId": "42fd37ff-38d0-4684-a558-696a4259a52c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': '4',\n",
              "  'tokens': ['practice',\n",
              "   ',',\n",
              "   'the',\n",
              "   'output',\n",
              "   'from',\n",
              "   'these',\n",
              "   'systems',\n",
              "   'needs',\n",
              "   'to',\n",
              "   'be',\n",
              "   'edited',\n",
              "   'to',\n",
              "   'correct',\n",
              "   'errors',\n",
              "   '.',\n",
              "   'A',\n",
              "   'way',\n",
              "   'of',\n",
              "   'increasing',\n",
              "   'the',\n",
              "   'productivity',\n",
              "   'of',\n",
              "   'the',\n",
              "   'whole',\n",
              "   'translation',\n",
              "   'process',\n",
              "   '(',\n",
              "   'MT',\n",
              "   'plus',\n",
              "   'human'],\n",
              "  'labels': ['O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'B',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'B',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'B',\n",
              "   'I',\n",
              "   'O',\n",
              "   'B',\n",
              "   'O',\n",
              "   'O']}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = tokenize_and_align_labels(train_sequences[4:5])\n",
        "print(q)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRHMWRHRHq_f",
        "outputId": "895d62cf-5cde-4784-e89a-dbdedd17af25"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 3218, 1010, 1996, 6434, 2013, 2122, 3001, 3791, 2000, 2022, 5493, 2000, 6149, 10697, 1012, 1037, 2126, 1997, 4852, 1996, 15836, 1997, 1996, 2878, 5449, 2832, 1006, 11047, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', -100]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token, label in zip(tokenizer.convert_ids_to_tokens(q[\"input_ids\"][0]),q[\"labels\"][0]):\n",
        "    print(f\"{token:_<40} {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrIxgauPIIHq",
        "outputId": "5d2bb629-117b-4602-a59e-50307b0a7bd4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]___________________________________ -100\n",
            "practice________________________________ O\n",
            ",_______________________________________ O\n",
            "the_____________________________________ O\n",
            "output__________________________________ B\n",
            "from____________________________________ O\n",
            "these___________________________________ O\n",
            "systems_________________________________ O\n",
            "needs___________________________________ O\n",
            "to______________________________________ O\n",
            "be______________________________________ O\n",
            "edited__________________________________ O\n",
            "to______________________________________ O\n",
            "correct_________________________________ O\n",
            "errors__________________________________ B\n",
            "._______________________________________ O\n",
            "a_______________________________________ O\n",
            "way_____________________________________ O\n",
            "of______________________________________ O\n",
            "increasing______________________________ O\n",
            "the_____________________________________ O\n",
            "productivity____________________________ O\n",
            "of______________________________________ O\n",
            "the_____________________________________ O\n",
            "whole___________________________________ O\n",
            "translation_____________________________ B\n",
            "process_________________________________ I\n",
            "(_______________________________________ O\n",
            "mt______________________________________ B\n",
            "[SEP]___________________________________ -100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Applying on entire data\n",
        "# tokenized_datasets = train_sequences.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "tokenized_datasets = [tokenize_and_align_labels([example]) for example in train_sequences]\n",
        "# Using list comprehension to apply the function element-wise\n",
        "# Notice: tokenize_and_align_labels expects a list of examples, so we wrap each example in a list\n"
      ],
      "metadata": {
        "id": "AUrRFtDIKOzU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYQycOXXKcXT",
        "outputId": "6e339b5e-b8cd-4f1d-a855-2b1790234542"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101,\n",
              "   1999,\n",
              "   2023,\n",
              "   3720,\n",
              "   2057,\n",
              "   6848,\n",
              "   2195,\n",
              "   12046,\n",
              "   2015,\n",
              "   1997,\n",
              "   2522,\n",
              "   5886,\n",
              "   10127,\n",
              "   4225,\n",
              "   2478,\n",
              "   2415,\n",
              "   2075,\n",
              "   3399,\n",
              "   1998,\n",
              "   8556,\n",
              "   1996,\n",
              "   6179,\n",
              "   2791,\n",
              "   1997,\n",
              "   2107,\n",
              "   12046,\n",
              "   2015,\n",
              "   2005,\n",
              "   2592,\n",
              "   102]],\n",
              " 'attention_mask': [[1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1]],\n",
              " 'labels': [[-100,\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'B',\n",
              "   'B',\n",
              "   'I',\n",
              "   'I',\n",
              "   'I',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'B',\n",
              "   'B',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'B',\n",
              "   'B',\n",
              "   'O',\n",
              "   'O',\n",
              "   -100]]}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining model\n",
        "ner_model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "10644bf16b1d464f97ec475d46700dd0",
            "c4225b5059424dba8a5df1a88c4db42b",
            "baf474c14bcc435092fc3d3bad4b3ed4",
            "5f755454b5234f1481d0bf044e07f636",
            "d6d18eaf51e04664aca3053e598d8ccf",
            "ec5a088e74ce44b8bdcddef5666f5d6a",
            "141c94e3e0fb4b71975f146f126d2ef5",
            "c93d55a432864231abc07afc30a96fdd",
            "37e165b96a744b19883d39f77f336ebd",
            "39b9ddfdd05347e8af7c48340d8a7118",
            "0cbe1a0e2d9d486099b1c299ed0a1b40"
          ]
        },
        "id": "OQJK0ai0K9hR",
        "outputId": "6f8d9817-8521-4093-d322-06cae3f3d646"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10644bf16b1d464f97ec475d46700dd0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import accelerate\n",
        "import transformers\n",
        "\n",
        "transformers.__version__, accelerate.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w9D63YDjlv1",
        "outputId": "cab5d055-011a-4661-943f-a114171b5aba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('4.46.3', '1.1.1')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Define training args\n",
        "from transformers import TrainingArguments, Trainer\n",
        "args = TrainingArguments(\n",
        "\"test-ner\",\n",
        "evaluation_strategy = \"epoch\",\n",
        "learning_rate=2e-5,\n",
        "per_device_train_batch_size=16,\n",
        "per_device_eval_batch_size=16,\n",
        "num_train_epochs=1,\n",
        "weight_decay=0.01,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zzhyXXaVuXV",
        "outputId": "67aed463-d5bd-4129-9c1d-e4eed714dee2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ],
      "metadata": {
        "id": "k7aF-WtEjnLp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install seqeval\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1bKyEG2jqru",
        "outputId": "6bc9ed32-a10b-48a8-c630-260d154e15c3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=e0b983de118977ea36882eb5437de8142b97a0581f0829095917570feb06580f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define the label names (update this with your own class names)\n",
        "# labels = ['O', 'B', 'I']  # Example labels\n",
        "\n",
        "# # Create the label-to-id and id-to-label mappings\n",
        "# label2id = {label: i for i, label in enumerate(labels)}\n",
        "# id2label = {i: label for i, label in enumerate(labels)}\n",
        "\n",
        "# # Pass these mappings to the model\n",
        "# ner_model.config.label2id = label2id\n",
        "# ner_model.config.id2label = id2label\n"
      ],
      "metadata": {
        "id": "0MrvjGVCsbYT"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = train_data[\"label\"]\n",
        "label_list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "qZxk4N-x6FF-",
        "outputId": "20d5422e-f679-45ba-d6f1-e0f8c4fd2ef1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        O\n",
              "1        O\n",
              "2        O\n",
              "3        O\n",
              "4        O\n",
              "        ..\n",
              "26737    O\n",
              "26738    B\n",
              "26739    I\n",
              "26740    I\n",
              "26741    O\n",
              "Name: label, Length: 26742, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26737</th>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26738</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26739</th>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26740</th>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26741</th>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26742 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    pred_logits, labels = eval_preds\n",
        "    print(eval_preds)\n",
        "\n",
        "    # Get the predicted labels by applying argmax\n",
        "    pred_labels = np.argmax(pred_logits, axis=2)\n",
        "\n",
        "    # Define the label list (you should have this from your model's configuration)\n",
        "    # Example: label_list = ['O', 'B-PER', 'I-PER', ...]\n",
        "\n",
        "    label_list = ['O', 'B', 'I']  # Update this according to your task\n",
        "\n",
        "    # Remove all the values where the label is -100 (ignored index)\n",
        "    predictions = [\n",
        "        [label_list[pred] for pred, l in zip(pred_seq, label_seq) if l != -100]\n",
        "        for pred_seq, label_seq in zip(pred_labels, labels)\n",
        "    ]\n",
        "\n",
        "    true_labels = [\n",
        "        [label_list[l] for l in label_seq if l != -100]\n",
        "        for label_seq in labels\n",
        "    ]\n",
        "\n",
        "    # Calculate precision, recall, F1, and accuracy using seqeval metrics\n",
        "    precision = precision_score(true_labels, predictions)\n",
        "    recall = recall_score(true_labels, predictions)\n",
        "    f1 = f1_score(true_labels, predictions)\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"accuracy\": accuracy,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "jKEPmVFXjsyh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset:\n",
        "    def __init__(self, encodings):\n",
        "        \"\"\"\n",
        "        Initialize the dataset with tokenized encodings.\n",
        "\n",
        "        Args:\n",
        "            encodings (dict): A dictionary containing 'input_ids', 'attention_mask', and 'labels'.\n",
        "        \"\"\"\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Get a single sample from the dataset.\n",
        "\n",
        "        Args:\n",
        "            idx (int): The index of the sample to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary containing 'input_ids', 'attention_mask', and 'labels' for the given index.\n",
        "        \"\"\"\n",
        "        return {key: val[idx] for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Get the total number of samples in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: The number of samples.\n",
        "        \"\"\"\n",
        "        return len(self.encodings[\"input_ids\"])\n"
      ],
      "metadata": {
        "id": "IVWJDPFAkk4q"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(dataset):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        [example[\"tokens\"] for example in dataset],  # List of token sequences\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128,\n",
        "        is_split_into_words=True\n",
        "    )\n",
        "\n",
        "    label_mapping = {'O': 0, 'B': 1, 'I': 2}  # Adjust as needed\n",
        "    labels = []\n",
        "\n",
        "    for i, example in enumerate(dataset):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        aligned_labels = []\n",
        "        for word_id in word_ids:\n",
        "            if word_id is None:\n",
        "                aligned_labels.append(-100)  # Ignore this token\n",
        "            else:\n",
        "                aligned_labels.append(label_mapping.get(example[\"labels\"][word_id], -100))\n",
        "        labels.append(aligned_labels)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "# Prepare the train and dev encodings\n",
        "train_encodings = tokenize_and_align_labels(train_sequences)\n",
        "dev_encodings = tokenize_and_align_labels(dev_sentences)\n"
      ],
      "metadata": {
        "id": "MXLQtm3SlyA9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_encodings)\n",
        "dev_dataset = CustomDataset(dev_encodings)\n"
      ],
      "metadata": {
        "id": "A-MhEO3-lx9i"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))  # Total training samples\n",
        "print(train_dataset[0])    # Example of a single sample\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bt_Ec-UmQbN",
        "outputId": "18604eac-ac72-4008-f170-3d78348dffe3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "892\n",
            "{'input_ids': [101, 1999, 2023, 3720, 2057, 6848, 2195, 12046, 2015, 1997, 2522, 5886, 10127, 4225, 2478, 2415, 2075, 3399, 1998, 8556, 1996, 6179, 2791, 1997, 2107, 12046, 2015, 2005, 2592, 13063, 1999, 6882, 3793, 4245, 1012, 2057, 10197, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [-100, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 0, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",           # Output directory\n",
        "    evaluation_strategy=\"epoch\",     # Evaluate every epoch\n",
        "    logging_dir=\"./logs\",            # Directory for logs\n",
        "    logging_steps=10,                # Log every 10 steps\n",
        "    per_device_train_batch_size=8,   # Batch size for training\n",
        "    per_device_eval_batch_size=16,   # Batch size for evaluation\n",
        "    num_train_epochs=3,              # Total number of training epochs\n",
        "    save_strategy=\"epoch\",           # Save model every epoch\n",
        "    load_best_model_at_end=True,     # Load the best model at the end\n",
        "    logging_first_step=True,         # Log the first training step\n",
        "    save_total_limit=2,              # Save only the 2 most recent models\n",
        "    remove_unused_columns=False,     # Keep unused columns for metrics\n",
        "    fp16=True,                       # Use mixed precision (if supported by GPU)\n",
        "    report_to=[\"none\"],              # Logging options: \"none\", \"tensorboard\", etc.\n",
        ")\n",
        "\n",
        "# Pass `training_args` to the Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=ner_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIE9MTZxmACb",
        "outputId": "0ac7db7c-76d0-4efd-86d5-f4b6212c0d7a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",           # Output directory\n",
        "    evaluation_strategy=\"epoch\",     # Evaluate every epoch\n",
        "    logging_dir=\"./logs\",            # Directory for logs\n",
        "    logging_steps=10,                # Log every 10 steps\n",
        "    per_device_train_batch_size=8,   # Batch size for training\n",
        "    per_device_eval_batch_size=16,   # Batch size for evaluation\n",
        "    num_train_epochs=10,              # Total number of training epochs\n",
        "    save_strategy=\"epoch\",           # Save model every epoch\n",
        "    load_best_model_at_end=True,     # Load the best model at the end\n",
        "    logging_first_step=True,         # Log the first training step\n",
        "    save_total_limit=2,              # Save only the 2 most recent models\n",
        "    remove_unused_columns=False,     # Keep unused columns for metrics\n",
        "    fp16=True,                       # Use mixed precision (if supported by GPU)\n",
        "    report_to=[\"none\"],              # Logging options: \"none\", \"tensorboard\", etc.\n",
        ")\n",
        "\n",
        "# Pass `training_args` to the Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=ner_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "yAMNgB6bMCCr",
        "outputId": "f67e55b8-221b-4e6d-f0db-64ecd2b9fa7b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1120' max='1120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1120/1120 03:18, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.215100</td>\n",
              "      <td>0.472328</td>\n",
              "      <td>0.575000</td>\n",
              "      <td>0.582278</td>\n",
              "      <td>0.578616</td>\n",
              "      <td>0.845308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.155400</td>\n",
              "      <td>0.500828</td>\n",
              "      <td>0.579882</td>\n",
              "      <td>0.620253</td>\n",
              "      <td>0.599388</td>\n",
              "      <td>0.849330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.110600</td>\n",
              "      <td>0.607814</td>\n",
              "      <td>0.577912</td>\n",
              "      <td>0.604430</td>\n",
              "      <td>0.590874</td>\n",
              "      <td>0.840214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.621673</td>\n",
              "      <td>0.567883</td>\n",
              "      <td>0.615506</td>\n",
              "      <td>0.590737</td>\n",
              "      <td>0.845308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.040900</td>\n",
              "      <td>0.787145</td>\n",
              "      <td>0.581359</td>\n",
              "      <td>0.582278</td>\n",
              "      <td>0.581818</td>\n",
              "      <td>0.851743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.019600</td>\n",
              "      <td>0.866389</td>\n",
              "      <td>0.564214</td>\n",
              "      <td>0.618671</td>\n",
              "      <td>0.590189</td>\n",
              "      <td>0.843432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.010700</td>\n",
              "      <td>0.949016</td>\n",
              "      <td>0.554804</td>\n",
              "      <td>0.648734</td>\n",
              "      <td>0.598104</td>\n",
              "      <td>0.843700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>0.933034</td>\n",
              "      <td>0.567055</td>\n",
              "      <td>0.615506</td>\n",
              "      <td>0.590288</td>\n",
              "      <td>0.848525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.007400</td>\n",
              "      <td>0.955192</td>\n",
              "      <td>0.574128</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.598485</td>\n",
              "      <td>0.849062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.995693</td>\n",
              "      <td>0.577259</td>\n",
              "      <td>0.626582</td>\n",
              "      <td>0.600910</td>\n",
              "      <td>0.845576</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<transformers.trainer_utils.EvalPrediction object at 0x7f0c7aa3d780>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f0c7a40e710>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f0c7a4d0ac0>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f0c7aa3d780>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f0c7ae38340>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f0c7a52a110>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f0c7a48f370>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f0c7a5c8550>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f0c7a7fbbe0>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f0c7a6e2530>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1120, training_loss=0.06252286624762096, metrics={'train_runtime': 198.1546, 'train_samples_per_second': 45.015, 'train_steps_per_second': 5.652, 'total_flos': 582697035601920.0, 'train_loss': 0.06252286624762096, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZPVJuCUIMBwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "pelCCEjnLn71",
        "outputId": "1c1ecfd9-52a4-4f18-b15b-8b910459a064"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='336' max='336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [336/336 01:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.309900</td>\n",
              "      <td>0.407446</td>\n",
              "      <td>0.615514</td>\n",
              "      <td>0.577532</td>\n",
              "      <td>0.595918</td>\n",
              "      <td>0.849062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.210900</td>\n",
              "      <td>0.421951</td>\n",
              "      <td>0.588685</td>\n",
              "      <td>0.609177</td>\n",
              "      <td>0.598756</td>\n",
              "      <td>0.847989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.197800</td>\n",
              "      <td>0.469766</td>\n",
              "      <td>0.576369</td>\n",
              "      <td>0.632911</td>\n",
              "      <td>0.603318</td>\n",
              "      <td>0.845845</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<transformers.trainer_utils.EvalPrediction object at 0x7f0c7a64d450>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f0c7a572a10>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f0c7a56b520>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=336, training_loss=0.2849602440283412, metrics={'train_runtime': 74.0276, 'train_samples_per_second': 36.149, 'train_steps_per_second': 4.539, 'total_flos': 174809110680576.0, 'train_loss': 0.2849602440283412, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.train()  # Start training\n",
        "\n",
        "# After training, evaluate and print results\n",
        "results = trainer.evaluate()\n",
        "print(\"Evaluation Results:\", results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "L8YsAXe1srNp",
        "outputId": "fc680179-3311-4d04-a9e2-62ddbde19564"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<transformers.trainer_utils.EvalPrediction object at 0x7f0c7aa0a470>\n",
            "Evaluation Results: {'eval_loss': 0.4723280370235443, 'eval_precision': 0.575, 'eval_recall': 0.5822784810126582, 'eval_f1': 0.5786163522012578, 'eval_accuracy': 0.8453083109919571, 'eval_runtime': 0.3474, 'eval_samples_per_second': 316.61, 'eval_steps_per_second': 20.148, 'epoch': 10.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import torch\n",
        "\n",
        "def plot_confusion_matrix(model, test_dataset, label_list, tokenizer):\n",
        "    \"\"\"\n",
        "    Plots a confusion matrix for the predictions on the test dataset.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    # Define the label-to-id and id-to-label mappings (assuming label_list contains your labels)\n",
        "    label2id = {label: i for i, label in enumerate(label_list)}\n",
        "    id2label = {i: label for i, label in enumerate(label_list)}\n",
        "\n",
        "    # Get the device the model is on\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Iterate through the test dataset and collect predictions and true labels\n",
        "    for batch in test_dataset:\n",
        "        # Convert token IDs back to words using the tokenizer\n",
        "        sentences = tokenizer.batch_decode(batch[\"input_ids\"], skip_special_tokens=True)  # Decode token IDs to sentences\n",
        "        inputs = tokenizer(sentences, padding=True, truncation=True, is_split_into_words=True, return_tensors=\"pt\").to(device)\n",
        "        labels = batch[\"labels\"]  # Assuming labels are in 'labels' key\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=2).detach().cpu().numpy()\n",
        "\n",
        "        # Convert predictions and true labels to label strings\n",
        "        # Fix the iteration to handle predictions and labels correctly\n",
        "        for pred_seq, label_seq in zip(preds, labels):\n",
        "            preds_tokens = [id2label[p] for p, l in zip(pred_seq, label_seq) if l != -100]\n",
        "            true_tokens = [id2label[l] for l in label_seq if l != -100]\n",
        "\n",
        "            predictions.append(preds_tokens)\n",
        "            true_labels.append(true_tokens)\n",
        "\n",
        "    # Flatten the predictions and labels\n",
        "    flat_preds = [label for seq in predictions for label in seq]\n",
        "    flat_true = [label for seq in true_labels for label in seq]\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(flat_true, flat_preds, labels=label_list)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_list)\n",
        "\n",
        "    # Plot the confusion matrix\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    disp.plot(cmap=plt.cm.Blues, xticks_rotation=90)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "# Usage example:\n",
        "# Assuming `test_sentences` is your raw test data (sentences with words) and `label_list` is defined\n",
        "test_encodings = tokenize_and_align_labels(test_sentences)  # Tokenize test data\n",
        "test_dataset = CustomDataset(test_encodings)  # Create a CustomDataset instance\n",
        "plot_confusion_matrix(ner_model, test_dataset, label_list, tokenizer)  # Pass to the confusion matrix plotter\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "62C_xtuxlxrT",
        "outputId": "69e57e14-127e-4b62-bf17-665be93fac9a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'int' object is not iterable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-b1492d756515>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mtest_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_and_align_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentences\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Tokenize test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_encodings\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Create a CustomDataset instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mner_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Pass to the confusion matrix plotter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-52-b1492d756515>\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(model, test_dataset, label_list, tokenizer)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Fix the iteration to handle predictions and labels correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpred_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_seq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mpreds_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mid2label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_seq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mtrue_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mid2label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_seq\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v00cz3Yflxgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ig7tsl3RlHg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AEONuWjVS31a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ehZayp8yS3nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "# Save the model and tokenizer\n",
        "def save_model(model, tokenizer, output_dir):\n",
        "    \"\"\"\n",
        "    Saves the model and tokenizer to the specified directory.\n",
        "    \"\"\"\n",
        "    model.save_pretrained(output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    print(f\"Model and tokenizer saved to {output_dir}\")\n",
        "\n",
        "# Example usage:\n",
        "output_dir = \"./ner_model\"\n",
        "save_model(ner_model, tokenizer, output_dir)\n",
        "\n",
        "# Load the model and tokenizer for inference\n",
        "def load_model(output_dir):\n",
        "    \"\"\"\n",
        "    Loads the model and tokenizer from the specified directory.\n",
        "    \"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
        "    model = AutoModelForTokenClassification.from_pretrained(output_dir)\n",
        "    return model, tokenizer\n",
        "\n",
        "# Example usage:\n",
        "model, tokenizer = load_model(output_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPt07GFbS3Ul",
        "outputId": "9b14aa48-f442-45e4-b259-9555e8dff169"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to ./ner_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def predict_ner(text, model, tokenizer, id2label):\n",
        "    \"\"\"\n",
        "    Performs NER on the given text using the trained model.\n",
        "    Args:\n",
        "        text (str): The input text for NER.\n",
        "        model: The trained NER model.\n",
        "        tokenizer: Tokenizer corresponding to the model.\n",
        "        id2label (dict): Mapping of label IDs to label names.\n",
        "\n",
        "    Returns:\n",
        "        List of tuples: Each tuple contains a token and its predicted label.\n",
        "    \"\"\"\n",
        "    # Tokenize input text without setting `is_split_into_words=True`\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get the predicted labels\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=2).squeeze().tolist()\n",
        "\n",
        "    # Map predictions to labels\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze().tolist())\n",
        "    labels = [id2label[pred] for pred in predictions]\n",
        "\n",
        "    # Pair tokens with labels, excluding special tokens ([CLS], [SEP], etc.)\n",
        "    predictions_with_labels = [\n",
        "        (token, label) for token, label in zip(tokens, labels) if token not in tokenizer.all_special_tokens\n",
        "    ]\n",
        "    return predictions_with_labels\n",
        "\n",
        "# Example usage:\n",
        "text = \"This paper aims to solve machine translation tagging problem using neural networks.\"\n",
        "id2label = {0: \"O\", 1: \"B\", 2: \"I\"}  # Replace with your actual mapping\n",
        "predictions = predict_ner(text, model, tokenizer, id2label)\n",
        "\n",
        "# Display the predictions\n",
        "for token, label in predictions:\n",
        "    print(f\"{token}: {label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1EQgM-LS7Xq",
        "outputId": "5db2ec97-2318-4255-a32e-1e370208b497"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this: O\n",
            "paper: O\n",
            "aims: O\n",
            "to: O\n",
            "solve: O\n",
            "machine: B\n",
            "translation: I\n",
            "tag: I\n",
            "##ging: I\n",
            "problem: I\n",
            "using: O\n",
            "neural: B\n",
            "networks: I\n",
            ".: O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def predict_ner(text, model, tokenizer, id2label):\n",
        "    \"\"\"\n",
        "    Performs NER on the given text using the trained model.\n",
        "    Args:\n",
        "        text (str): The input text for NER.\n",
        "        model: The trained NER model.\n",
        "        tokenizer: Tokenizer corresponding to the model.\n",
        "        id2label (dict): Mapping of label IDs to label names.\n",
        "\n",
        "    Returns:\n",
        "        List of tuples: Each tuple contains a token and its predicted label.\n",
        "    \"\"\"\n",
        "    # Tokenize input text without setting `is_split_into_words=True`\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get the predicted labels\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=2).squeeze().tolist()\n",
        "\n",
        "    # Map predictions to labels\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze().tolist())\n",
        "    labels = [id2label[pred] for pred in predictions]\n",
        "\n",
        "    # Apply B/I rule: If a token belongs to an entity, ensure the first token is \"B\" and the rest are \"I\"\n",
        "    new_labels = []\n",
        "    inside_entity = False\n",
        "    for i, (token, label) in enumerate(zip(tokens, labels)):\n",
        "        # Exclude special tokens ([CLS], [SEP], etc.)\n",
        "        if token in tokenizer.all_special_tokens:\n",
        "            continue\n",
        "\n",
        "        if label == \"O\":  # If it's outside any entity\n",
        "            inside_entity = False\n",
        "            new_labels.append(label)\n",
        "        else:\n",
        "            if not inside_entity:  # Start of a new entity\n",
        "                new_labels.append(\"B\")\n",
        "                inside_entity = True\n",
        "            else:  # Inside an entity\n",
        "                new_labels.append(\"I\")\n",
        "\n",
        "    # Pair tokens with labels, excluding special tokens\n",
        "    predictions_with_labels = [\n",
        "        (token, label) for token, label in zip(tokens, new_labels) if token not in tokenizer.all_special_tokens\n",
        "    ]\n",
        "\n",
        "    return predictions_with_labels\n",
        "\n",
        "# Example usage:\n",
        "text = \"This paper aims to solve machine translation tagging problem using neural networks.\"\n",
        "id2label = {0: \"O\", 1: \"B\", 2: \"I\"}  # Replace with your actual mapping\n",
        "predictions = predict_ner(text, model, tokenizer, id2label)\n",
        "\n",
        "# Display the predictions\n",
        "for token, label in predictions:\n",
        "    print(f\"{token}: {label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g_k5yN6TR8P",
        "outputId": "89f1e83f-7896-47cf-fc6c-8b8d6d138902"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this: O\n",
            "paper: O\n",
            "aims: O\n",
            "to: O\n",
            "solve: B\n",
            "machine: I\n",
            "translation: I\n",
            "tag: I\n",
            "##ging: I\n",
            "problem: O\n",
            "using: B\n",
            "neural: I\n",
            "networks: O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import numpy as np\n",
        "\n",
        "# Function to predict labels for a given sentence using a trained model\n",
        "def predict_ner(sentence, model, tokenizer, id2label):\n",
        "    \"\"\"\n",
        "    Predict named entities for a sentence using a NER model.\n",
        "    Args:\n",
        "        sentence (str): Input sentence.\n",
        "        model: Pre-trained NER model.\n",
        "        tokenizer: Tokenizer associated with the model.\n",
        "        id2label (dict): Mapping from label IDs to label names.\n",
        "    \"\"\"\n",
        "    # Tokenize the input sentence\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Get predictions from the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get predicted labels from the outputs\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    # Convert predicted token IDs to labels\n",
        "    predicted_labels = [id2label[pred.item()] for pred in predictions[0]]\n",
        "\n",
        "    # Return tokens and corresponding predicted labels\n",
        "    return inputs.tokens(), predicted_labels\n",
        "\n",
        "def evaluate_model_on_test_sentences(test_sentences, model, tokenizer, id2label):\n",
        "    \"\"\"\n",
        "    Evaluate a saved model on a list of tokenized test sentences with their labels.\n",
        "    Args:\n",
        "        test_sentences (list): List of dictionaries with 'tokens' and 'labels'.\n",
        "        model: Trained NER model.\n",
        "        tokenizer: Tokenizer for the model.\n",
        "        id2label (dict): Mapping from label IDs to label names.\n",
        "    \"\"\"\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    for sentence_data in test_sentences:\n",
        "        tokens = sentence_data['tokens']\n",
        "        true_sentence_labels = sentence_data['labels']\n",
        "\n",
        "        if len(tokens) <= 1:\n",
        "            print(f\"Skipping sentence with only one token or punctuation: {' '.join(tokens)}\")\n",
        "            continue\n",
        "\n",
        "        # Join tokens back into a sentence for tokenization\n",
        "        sentence = \" \".join(tokens)\n",
        "\n",
        "        # Get predictions for the sentence\n",
        "        print(f\"Processing sentence: {' '.join(tokens)}\")\n",
        "        predicted_tokens, predicted_labels_for_sentence = predict_ner(sentence, model, tokenizer, id2label)\n",
        "\n",
        "        if predicted_labels_for_sentence:\n",
        "            # Remove special tokens (like [CLS], [SEP], etc.) from both true and predicted labels\n",
        "            filtered_true_labels = []\n",
        "            filtered_pred_labels = []\n",
        "\n",
        "            true_label_idx = 0\n",
        "            for i, token in enumerate(predicted_tokens):\n",
        "                if token not in tokenizer.all_special_tokens:\n",
        "                    # Repeat the true label for subword tokens\n",
        "                    if true_label_idx < len(true_sentence_labels):  # Check if index is within bounds\n",
        "                        filtered_true_labels.append(true_sentence_labels[true_label_idx])\n",
        "                        filtered_pred_labels.append(predicted_labels_for_sentence[i])\n",
        "\n",
        "                    # Move to the next true label after handling one word\n",
        "                    if not token.startswith(\"##\"):  # if it's not a subword token\n",
        "                        true_label_idx += 1\n",
        "\n",
        "            # Ensure the true labels and predicted labels align\n",
        "            true_labels.extend(filtered_true_labels)\n",
        "            predicted_labels.extend(filtered_pred_labels)\n",
        "\n",
        "        else:\n",
        "            print(f\"Prediction missing for sentence: {' '.join(tokens)}\")\n",
        "\n",
        "    # Check if lengths match\n",
        "    if len(true_labels) != len(predicted_labels):\n",
        "        print(f\"Warning: Mismatch in number of true labels and predicted labels.\")\n",
        "        print(f\"True labels length: {len(true_labels)}\")\n",
        "        print(f\"Predicted labels length: {len(predicted_labels)}\")\n",
        "\n",
        "    # Evaluate using classification report and confusion matrix\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(true_labels, predicted_labels))\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "    # Plot the confusion matrix\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=id2label.values(), yticklabels=id2label.values())\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# 1. Load the trained model and tokenizer from the saved directory\n",
        "model_dir = \"./ner_model\"  # Path to your saved model directory\n",
        "tokenizer_dir = model_dir  # Path to your saved tokenizer directory\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_dir)\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_dir)\n",
        "\n",
        "# 2. Define your id2label mapping\n",
        "id2label = {0: \"O\", 1: \"B\", 2: \"I\"}  # Replace with your actual mapping\n",
        "\n",
        "# 3. Evaluate the model on the test dataset\n",
        "csv_path = \"data_test.csv\"  # Replace with the actual CSV file path\n",
        "evaluate_model_on_test_sentences(test_sentences, model, tokenizer, id2label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GiypDQlkUVZn",
        "outputId": "a94589ff-c5ab-4053-d44e-51530a34ed62"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing sentence: Systems based on synchronous grammars and tree transducers promise to improve the quality of statistical machine translation output , but are often very computationally intensive . The complexity is exponential\n",
            "Processing sentence: in the size of individual grammar rules due to arbitrary re orderings between the two languages . We develop a theory of binarization for synchronous context free grammars and present\n",
            "Processing sentence: a linear time algorithm for binarizing synchronous rules when possible . In our large scale experiments , we found that almost all rules are binarizable and the resulting binarized rule\n",
            "Processing sentence: set significantly improves the speed and accuracy of a state of the art syntax based machine translation system . We also discuss the more general , and computationally more difficult\n",
            "Processing sentence: , problem of finding good parsing strategies for non binarizable rules , and present an approximate polynomial time algorithm for this problem . Many NLP applications entail that texts are\n",
            "Processing sentence: classified based on their semantic distance ( how similar or different the texts are ) . For example , comparing the text of a new document to that of documents\n",
            "Processing sentence: of known topics can help identify the topic of the new text . Typically , a distributional distance is used to capture the implicit semantic distance between two pieces of\n",
            "Processing sentence: text . However , such approaches do not take into account the semantic relations between words . In this article , we introduce an alternative method of measuring the semantic\n",
            "Processing sentence: distance between texts that integrates distributional information and ontological knowledge within a network flow formalism . We first represent each text as a collection of frequency - weighted concepts within\n",
            "Processing sentence: an ontology . We then make use of a network flow method which provides an efficient way of explicitly measuring the frequency - weighted ontological distance between the concepts across\n",
            "Processing sentence: two texts . We evaluate our method in a variety of NLP tasks , and find that it performs well on two of three tasks . We develop a new\n",
            "Processing sentence: measure of semantic coherence that enables us to account for the performance difference across the three data sets , shedding light on the properties of a data set that lends\n",
            "Processing sentence: itself well to our method . Recent work in natural language generation has begun to take linguistic variation into account , developing algorithms that are capable of modifying the system\n",
            "Processing sentence: 's linguistic style based either on the user 's linguistic style or other factors , such as personality or politeness . While stylistic control has traditionally relied on handcrafted rules\n",
            "Processing sentence: , statistical methods are likely to be needed for generation systems to scale to the production of the large range of variation observed in human dialogues . Previous work on\n",
            "Processing sentence: statistical natural language generation ( SNLG ) has shown that the grammaticality and naturalness of generated utterances can be optimized from data ; however these data - driven methods have\n",
            "Processing sentence: not been shown to produce stylistic variation that is perceived by humans in the way that the system intended . This paper describes Personage , a highly parameterizable language generator\n",
            "Processing sentence: whose parameters are based on psychological findings about the linguistic reflexes of personality . We present a novel SNLG method which uses parameter estimation models trained on personality - annotated\n",
            "Processing sentence: data to predict the generation decisions required to convey any combination of scalar values along the five main dimensions of personality . A human evaluation shows that parameter estimation models\n",
            "Processing sentence: produce recognizable stylistic variation along multiple dimensions , on a continuous scale , and without the computational cost incurred by overgeneration techniques . This article deals with deverbal nominalizations in\n",
            "Processing sentence: Spanish ; concretely , we focus on the denotative distinction between event and result nominalizations . The goals of this work is twofold : ï¬rst , to detect the most\n",
            "Processing sentence: relevant features for this denotative distinction ; and , second , to build an automatic classiï¬cation system of deverbal nominalizations according to their denotation . We have based our study\n",
            "Processing sentence: on theoretical hypotheses dealing with this semantic distinction and we have analyzed them empirically by means of Machine Learning techniques which are the basis of the ADN - Classiï¬er .\n",
            "Processing sentence: This is the ï¬rst tool that aims to automatically classify deverbal nominalizations in event , result , or underspeciï¬ed denotation types in Spanish . The ADN - Classiï¬er has helped\n",
            "Processing sentence: us to quantitatively evaluate the validity of our claims regarding deverbal nominalizations . We set up a series of experiments in order to test the ADN - Classiï¬er with different\n",
            "Processing sentence: models and in different realistic scenarios depending on the knowledge resources and natural language processors available . The ADN - Classiï¬er achieved good results ( 87.20 % accuracy ) .\n",
            "Processing sentence: Translation models used for statistical machine translation are compiled from parallel corpora that are manually translated . The common assumption is that parallel texts are symmetrical : The direction of\n",
            "Processing sentence: translation is deemed irrelevant and is consequently ignored . Much research in Translation Studies indicates that the direction of translation matters , however , as translated language ( translationese )\n",
            "Processing sentence: has many unique properties . It has already been shown that phrase tables constructed from parallel corpora translated in the same direction as the translation task outperform those constructed from\n",
            "Processing sentence: corpora translated in the opposite direction . We reconfirm that this is indeed the case , but emphasize the importance of also using texts translated in the â wrong â\n",
            "Processing sentence: direction . We take advantage of information pertaining to the direction of translation in constructing phrase tables by adapting the translation model to the special properties of translationese . We\n",
            "Processing sentence: explore two adaptation techniques : First , we create a mixture model by interpolating phrase tables trained on texts translated in the â right â and the â wrong â\n",
            "Processing sentence: directions . The weights for the interpolation are determined by minimizing perplexity . Second , we define entropy - based measures that estimate the correspondence of target - language phrases\n",
            "Processing sentence: to translationese , thereby eliminating the need to annotate the parallel corpus with information pertaining to the direction of translation . We show that incorporating these measures as features in\n",
            "Processing sentence: the phrase tables of statistical machine translation systems results in consistent , statistically significant improvement in the quality of the translation . As more and more Arabic textual information becomes\n",
            "Processing sentence: available through the Web in homes and businesses , via Internet and Intranet services , there is an urgent need for technologies and tools to process the relevant information .\n",
            "Processing sentence: Named Entity Recognition ( NER ) is an Information Extraction task that has become an integral part of many other Natural Language Processing ( NLP ) tasks , such as\n",
            "Processing sentence: Machine Translation and Information Retrieval . Arabic NER has begun to receive attention in recent years . The characteristics and peculiarities of Arabic , a member of the Semitic languages\n",
            "Processing sentence: family , make dealing with NER a challenge . The performance of an Arabic NER component affects the overall performance of the NLP system in a positive manner . This\n",
            "Processing sentence: article attempts to describe and detail the recent increase in interest and progress made in Arabic NER research . The importance of the NER task is demonstrated , the main\n",
            "Processing sentence: characteristics of the Arabic language are highlighted , and the aspects of standardization in annotating named entities are illustrated . Moreover , the different Arabic linguistic resources are presented and\n",
            "Processing sentence: the approaches used in Arabic NER field are explained . The features of common tools used in Arabic NER are described , and standard evaluation metrics are illustrated . In\n",
            "Processing sentence: addition , a review of the state of the art of Arabic NER research is discussed . Finally , we present our conclusions . Throughout the presentation , illustrative examples\n",
            "Processing sentence: are used for clarification . We present a statistical parsing framework for sentence - level sentiment classification in this article . Unlike previous works that use syntactic parsing results for\n",
            "Processing sentence: sentiment analysis , we develop a statistical parser to directly analyze the sentiment structure of a sentence . We show that complicated phenomena in sentiment analysis ( e.g. , negation\n",
            "Processing sentence: , intensification , and contrast ) can be handled the same way as simple and straightforward sentiment expressions in a unified and probabilistic way . We formulate the sentiment grammar\n",
            "Processing sentence: upon Context - Free Grammars ( CFGs ) , and provide a formal description of the sentiment parsing framework . We develop the parsing model to obtain possible sentiment parse\n",
            "Processing sentence: trees for a sentence , from which the polarity model is proposed to derive the sentiment strength and polarity , and the ranking model is dedicated to selecting the best\n",
            "Processing sentence: sentiment tree . We train the parser directly from examples of sentences annotated only with sentiment polarity labels but without any syntactic annotations or polarity annotations of constituents within sentences\n",
            "Processing sentence: . Therefore we can obtain training data easily . In particular , we train a sentiment parser , s.parser , from a large amount of review sentences with users '\n",
            "Processing sentence: ratings as rough sentiment polarity labels . Extensive experiments on existing benchmark data sets show significant improvements over baseline sentiment classification approaches . The most common approach in text mining\n",
            "Processing sentence: classification tasks is to rely on features like words , part - of - speech tags , stems , or some other high - level linguistic features . Recently ,\n",
            "Processing sentence: an approach that uses only character p - grams as features has been proposed for the task of native language identification ( NLI ) . The approach obtained state -\n",
            "Processing sentence: of - the - art results by combining several string kernels using multiple kernel learning . Despite the fact that the approach based on string kernels performs so well ,\n",
            "Processing sentence: several questions about this method remain unanswered . First , it is not clear why such a simple approach can compete with far more complex approaches that take words ,\n",
            "Processing sentence: lemmas , syntactic information , or even semantics into account . Second , although the approach is designed to be language independent , all experiments to date have been on\n",
            "Processing sentence: English . This work is an extensive study that aims to systematically present the string kernel approach and to clarify the open questions mentioned above . A broad set of\n",
            "Processing sentence: native language identification experiments were conducted to compare the string kernels approach with other state - of - the - art methods . The empirical results obtained in all of\n",
            "Processing sentence: the experiments conducted in this work indicate that the proposed approach achieves state - of - the - art performance in NLI , reaching an accuracy that is 1.7 %\n",
            "Processing sentence: above the top scoring system of the 2013 NLI Shared Task . Furthermore , the results obtained on both the Arabic and the Norwegian corpora demonstrate that the proposed approach\n",
            "Processing sentence: is language independent . In the Arabic native language identification task , string kernels show an increase of more than 17 % over the best accuracy reported so far .\n",
            "Processing sentence: The results of string kernels on Norwegian native language identification are also significantly better than the state - of - the - art approach . In addition , in a\n",
            "Processing sentence: cross - corpus experiment , the proposed approach shows that it can also be topic independent , improving the state - of - the - art system by 32.3 %\n",
            "Processing sentence: . To gain additional insights about the string kernels approach , the features selected by the classifier as being more discriminating are analyzed in this work . The analysis also\n",
            "Processing sentence: offers information about localized language transfer effects , since the features used by the proposed model are p - grams of various lengths . The features captured by the model\n",
            "Processing sentence: typically include stems , function words , and word prefixes and suffixes , which have the potential to generalize over purely word - based features . By analyzing the discriminating\n",
            "Processing sentence: features , this article offers insights into two kinds of language transfer effects , namely , word choice ( lexical transfer ) and morphological differences . The goal of the\n",
            "Processing sentence: current study is to give a full view of the string kernels approach and shed some light on why this approach works so well . Although there has been much\n",
            "Processing sentence: work in recent years on data - driven natural language generation , little attention has been paid to the fine - grained interactions that arise during microplanning between aggregation ,\n",
            "Processing sentence: surface realization , and sentence segmentation . In this article , we propose a hybrid symbolic / statistical approach to jointly model the constraints regulating these interactions . Our approach\n",
            "Processing sentence: integrates a small handwritten grammar , a statistical hypertagger , and a surface realization algorithm . It is applied to the verbalization of knowledge base queries and tested on 13\n",
            "Processing sentence: knowledge bases to demonstrate domain independence . We evaluate our approach in several ways . A quantitative analysis shows that the hybrid approach outperforms a purely symbolic approach in terms\n",
            "Processing sentence: of both speed and coverage . Results from a human study indicate that users find the output of this hybrid statistic / symbolic system more fluent than both a template\n",
            "Processing sentence: - based and a purely symbolic grammar based approach . Finally , we illustrate by means of examples that our approach can account for various factors impacting aggregation , sentence\n",
            "Processing sentence: segmentation , and surface realization . Orthographic similarities across languages provide a strong signal for unsupervised probabilistic transduction ( decipherment ) for closely related language pairs . The existing decipherment\n",
            "Processing sentence: models , however , are not well suited for exploiting these orthographic similarities . We propose a log - linear model with latent variables that incorporates orthographic similarity features .\n",
            "Processing sentence: Maximum likelihood training is computationally expensive for the proposed log - linear model . To address this challenge , we perform approximate inference via Markov chain Monte Carlo sampling and\n",
            "Processing sentence: contrastive divergence . Our results show that the proposed log - linear model with contrastive divergence outperforms the existing generative decipherment models by exploiting the orthographic features . The model\n",
            "Processing sentence: both scales to large vocabularies and preserves accuracy in low- and no - resource contexts . We present algorithms for extracting Hyperedge Replacement Grammar ( HRG ) rules from a\n",
            "Processing sentence: graph along with a vertex order . Our algorithms are based on finding a tree decomposition of smallest width , relative to the vertex order , and then extracting one\n",
            "Processing sentence: rule for each node in this structure . The assumption of a fixed order for the vertices of the input graph makes it possible to solve the problem in polynomial\n",
            "Processing sentence: time , in contrast to the fact that the problem of finding optimal tree decompositions for a graph is NP - hard . We also present polynomial - time algorithms\n",
            "Processing sentence: for parsing based on our HRGs , where the input is a vertex sequence and the output is a graph structure . The intended application of our algorithms is grammar\n",
            "Processing sentence: extraction and parsing for semantic representation of natural language . We apply our algorithms to data annotated with Abstract Meaning Representations and report on the characteristics of the resulting grammars\n",
            "Processing sentence: . Weighted deduction systems provide a framework for describing parsing algorithms that can be used with a variety of operations for combining the values of partial derivations . For some\n",
            "Processing sentence: operations , inside values can be computed efficiently , but outside values can not . We view out - side values as functions from inside values to the total value\n",
            "Processing sentence: of all derivations , and we analyze outside computation in terms of function composition . This viewpoint helps explain why efficient outside computation is possible in many settings , despite\n",
            "Processing sentence: the lack of a general outside algorithm for semiring operations . In this work , we present a phenomenon - oriented comparative analysis of the two dominant approaches in English\n",
            "Processing sentence: Resource Semantic ( ERS ) parsing : classic , knowledge - intensive and neural , data - intensive models . To reflect state - of - the - art neural\n",
            "Processing sentence: NLP technologies , a factorization - based parser is introduced that can produce Elementary Dependency Structures much more accurately than previous data - driven parsers . We conduct a suite\n",
            "Processing sentence: of tests for different linguistic phenomena to analyze the grammatical competence of different parsers , where we show that , despite comparable performance overall , knowledge- and data - intensive\n",
            "Processing sentence: models produce different types of errors , in a way that can be explained by their theoretical properties . This analysis is beneficial to in - depth evaluation of several\n",
            "Processing sentence: representative parsing techniques and leads to new directions for parser development . Annotation studies require annotators familiarize task annotation scheme data domain overwhelming beginning mentally taxing induce errors resulting annotations\n",
            "Processing sentence: especially citizen science crowdsourcing scenarios domain expertise required alleviate issues work proposes annotation curricula novel approach implicitly train annotators goal gradually introduce annotators task ordering instances annotated according learning curriculum\n",
            "Processing sentence: work formalizes annotation curricula sentence- paragraph level annotation tasks defines ordering strategy identifies performing heuristics interactively trained models existing English datasets Finally provide proof concept annotation curricula carefully designed user\n",
            "Processing sentence: study voluntary participants asked identify fitting misconception English tweets Covid-19 pandemic results indicate simple heuristic order instances significantly reduce total annotation time preserving high annotation quality Annotation curricula promising research\n",
            "Processing sentence: direction improve data collection facilitate future researchâfor instance adapt annotation curricula specific tasks expert annotation scenariosâall code data user study consisting 2,400 annotations available.1 Dependency - based approaches to syntactic\n",
            "Processing sentence: analysis assume that syntactic structure can be analyzed in terms of binary asymmetric dependency relations holding between elementary syntactic units . Computational models for dependency parsing almost universally assume that\n",
            "Processing sentence: an elementary syntactic unit is a word , while the influential theory of Lucien TesniÃ¨re instead posits a more abstract notion of nucleus , which may be realized as one\n",
            "Processing sentence: or more words . In this article , we investigate the effect of enriching computational parsing models with a concept of nucleus inspired by TesniÃ¨re . We begin by reviewing\n",
            "Processing sentence: how the concept of nucleus can be defined in the framework of Universal Dependencies , which has become the de facto standard for training and evaluating supervised dependency parsers ,\n",
            "Processing sentence: and explaining how composition functions can be used to make neural transition - based dependency parsers aware of the nuclei thus defined . We then perform an extensive experimental study\n",
            "Processing sentence: , using data from 20 languages to assess the impact of nucleus composition across languages with different typological characteristics , and utilizing a variety of analytical tools including ablation ,\n",
            "Processing sentence: linear mixed - effects models , diagnostic classifiers , and dimensionality reduction . The analysis reveals that nucleus composition gives small but consistent improvements in parsing accuracy for most languages\n",
            "Processing sentence: , and that the improvement mainly concerns the analysis of main predicates , nominal dependents , clausal dependents , and coordination structures . Significant factors explaining the rate of improvement\n",
            "Processing sentence: across languages include entropy in coordination structures and frequency of certain function words , in particular determiners . Analysis using dimensionality reduction and diagnostic classifiers suggests that nucleus composition increases\n",
            "Processing sentence: the similarity of vectors representing nuclei of the same syntactic type . Linguistic variation across a region of interest can be captured by partitioning the region into areas and using\n",
            "Processing sentence: social media data to train embeddings that represent language use in those areas . Recent work has focused on larger areas , such as cities or counties , to ensure\n",
            "Processing sentence: that enough social media data is available in each area , but larger areas have a limited ability to find fine-grained distinctions , such as intracity differences in language use\n",
            "Processing sentence: . We demonstrate that it is possible to embed smaller areas , which can provide higher resolution analyses of language variation . We embed voting precincts , which are tiny\n",
            "Processing sentence: , evenly sized political divisions for the administration of elections . The issue with modeling language use in small areas is that the data becomes incredibly sparse , with many\n",
            "Processing sentence: areas having scant social media data . We propose a novel embedding approach that alternates training with smoothing , which mitigates these sparsity issues . We focus on linguistic variation\n",
            "Processing sentence: across Texas as it is relatively understudied . We develop two novel quantitative evaluations that measure how well the embeddings can be used to capture linguistic variation . The first\n",
            "Processing sentence: evaluation measures how well a model can map a dialect given terms specific to that dialect . The second evaluation measures how well a model can map preference of lexical\n",
            "Processing sentence: variants . These evaluations show how embedding models could be used directly by sociolinguists and measure how much sociolinguistic information is contained within the embeddings . We complement this second\n",
            "Processing sentence: evaluation with a methodology for using embeddings as a kind of genetic code where we identify â genes â that correspond to a sociological variable and connect those â genes\n",
            "Processing sentence: â to a linguistic phenomenon thereby connecting sociological phenomena to linguistic ones . Finally , we explore approaches for inferring isoglosses using embeddings . Polysemy is the type of lexical\n",
            "Processing sentence: ambiguity where a word has multiple distinct but related interpretations . In the past decade , it has been the subject of a great many studies across multiple disciplines including\n",
            "Processing sentence: linguistics , psychology , neuroscience , and computational linguistics , which have made it increasingly clear that the complexity of polysemy precludes simple , universal answers , especially concerning the\n",
            "Processing sentence: representation and processing of polysemous words . But fuelled by the growing availability of large , crowdsourced datasets providing substantial empirical evidence ; improved behavioral methodology ; and the development\n",
            "Processing sentence: of contextualized language models capable of encoding the fine-grained meaning of a word within a given context , the literature on polysemy recently has developed more complex theoretical analyses .\n",
            "Processing sentence: In this survey we discuss these recent contributions to the investigation of polysemy against the backdrop of a long legacy of research across multiple decades and disciplines . Our aim\n",
            "Processing sentence: is to bring together different perspectives to achieve a more complete picture of the heterogeneity and complexity of the phenomenon of polysemy . Specifically , we highlight evidence supporting a\n",
            "Processing sentence: range of hybrid models of the mental processing of polysemes . These hybrid models combine elements from different previous theoretical approaches to explain patterns and idiosyncrasies in the processing of\n",
            "Processing sentence: polysemous that the best known models so far have failed to account for . Our literature review finds that ( i ) traditional analyses of polysemy can be limited in\n",
            "Processing sentence: their generalizability by loose definitions and selective materials ; ( ii ) linguistic tests provide useful evidence on individual cases , but fail to capture the full range of factors\n",
            "Processing sentence: involved in the processing of polysemous sense extensions ; and ( iii ) recent behavioral ( psycho ) linguistics studies , large-scale annotation efforts , and investigations leveraging contextualized language\n",
            "Processing sentence: models provide accumulating evidence suggesting that polysemous sense similarity covers a wide spectrum between identity of sense and homonymy-like unrelatedness of meaning . We hope that the interdisciplinary account of\n",
            "Processing sentence: polysemy provided in this survey inspires further fundamental research on the nature of polysemy and better equips applied research to deal with the complexity surrounding the phenomenon , for example\n",
            "Processing sentence: , by enabling the development of benchmarks and testing paradigms for large language models informed by a greater portion of the rich evidence on the phenomenon currently available .\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.47      0.65      0.55       470\n",
            "           I       0.64      0.66      0.65       621\n",
            "           O       0.92      0.87      0.90      3316\n",
            "\n",
            "    accuracy                           0.82      4407\n",
            "   macro avg       0.68      0.73      0.70      4407\n",
            "weighted avg       0.84      0.82      0.82      4407\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YHBKl8OAjs6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def print_sample_results(test_sentences, model, tokenizer, id2label, num_samples=5):\n",
        "    \"\"\"\n",
        "    Print a few sample results from test sentences, showing the predicted and actual labels.\n",
        "\n",
        "    Args:\n",
        "        test_sentences (list): List of dictionaries with 'tokens' and 'labels'.\n",
        "        model: Trained NER model.\n",
        "        tokenizer: Tokenizer for the model.\n",
        "        id2label (dict): Mapping from label IDs to label names.\n",
        "        num_samples (int): Number of samples to print.\n",
        "    \"\"\"\n",
        "    sample_sentences = random.sample(test_sentences, num_samples)  # Select random sample sentences\n",
        "\n",
        "    for sentence_data in sample_sentences:\n",
        "        tokens = sentence_data['tokens']\n",
        "        true_sentence_labels = sentence_data['labels']\n",
        "\n",
        "        # Join tokens back into a sentence for tokenization\n",
        "        sentence = \" \".join(tokens)\n",
        "\n",
        "        # Get predictions for the sentence\n",
        "        predicted_tokens, predicted_labels_for_sentence = predict_ner(sentence, model, tokenizer, id2label)\n",
        "\n",
        "        if predicted_labels_for_sentence:\n",
        "            # Align predicted labels and true labels\n",
        "            filtered_true_labels = []\n",
        "            filtered_pred_labels = []\n",
        "            true_label_idx = 0\n",
        "            for i, token in enumerate(predicted_tokens):\n",
        "                if token not in tokenizer.all_special_tokens:\n",
        "                    if true_label_idx < len(true_sentence_labels):  # Check if index is within bounds\n",
        "                        filtered_true_labels.append(true_sentence_labels[true_label_idx])\n",
        "                        filtered_pred_labels.append(predicted_labels_for_sentence[i])\n",
        "\n",
        "                    # Move to the next true label after handling one word\n",
        "                    if not token.startswith(\"##\"):  # if it's not a subword token\n",
        "                        true_label_idx += 1\n",
        "\n",
        "            # Print the sample sentence, predicted and actual labels\n",
        "            print(f\"Sentence: {' '.join(tokens)}\")\n",
        "            print(f\"True Labels: {filtered_true_labels}\")\n",
        "            print(f\"Predicted Labels: {filtered_pred_labels}\")\n",
        "            print(\"-\" * 80)\n",
        "        else:\n",
        "            print(f\"Prediction missing for sentence: {' '.join(tokens)}\")\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "# Example usage\n",
        "print_sample_results(test_sentences, model, tokenizer, id2label, num_samples=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YAlBq2deKEe",
        "outputId": "fa221832-1acb-45e7-9543-8e26a013e97d"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: has many unique properties . It has already been shown that phrase tables constructed from parallel corpora translated in the same direction as the translation task outperform those constructed from\n",
            "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------------------------------------\n",
            "Sentence: of known topics can help identify the topic of the new text . Typically , a distributional distance is used to capture the implicit semantic distance between two pieces of\n",
            "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O']\n",
            "Predicted Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------------------------------------\n",
            "Sentence: integrates a small handwritten grammar , a statistical hypertagger , and a surface realization algorithm . It is applied to the verbalization of knowledge base queries and tested on 13\n",
            "True Labels: ['O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'O']\n",
            "Predicted Labels: ['O', 'O', 'O', 'O', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------------------------------------\n",
            "Sentence: cross - corpus experiment , the proposed approach shows that it can also be topic independent , improving the state - of - the - art system by 32.3 %\n",
            "True Labels: ['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']\n",
            "Predicted Labels: ['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------------------------------------\n",
            "Sentence: native language identification experiments were conducted to compare the string kernels approach with other state - of - the - art methods . The empirical results obtained in all of\n",
            "True Labels: ['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted Labels: ['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kGwkeDKFkYkr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}