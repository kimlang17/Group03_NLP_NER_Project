Very 	 O
recently 	 O
, 	 O
few 	 O
certified 	 O
defense 	 O
methods 	 O
have 	 O
been 	 O
developed 	 O
to 	 O
provably 	 O
guarantee 	 O
the 	 O
robustness 	 B
of 	 O
a 	 O
text 	 B
classifier 	 I
to 	 O
adversarial 	 B
synonym 	 B
substitutions 	 I
. 	 O
However 	 O
, 	 O
all 	 O
the 	 O
existing 	 O
certified 	 O
defense 	 O
methods 	 O
assume 	 O
that 	 O
the 	 O
defenders 	 O
have 	 O
been 	 O
informed 	 O
of 	 O
how 	 O
the 	 O
adversaries 	 O
generate 	 O
synonyms 	 B
, 	 O
which 	 O
is 	 O
not 	 O
a 	 O
realistic 	 O
scenario 	 O
. 	 O
In 	 O
this 	 O
study 	 O
, 	 O
we 	 O
propose 	 O
a 	 O
certifiably 	 O
robust 	 B
defense 	 O
method 	 O
by 	 O
randomly 	 O
masking 	 O
a 	 O
certain 	 O
proportion 	 O
of 	 O
the 	 O
words 	 O
in 	 O
an 	 O
input 	 B
text 	 I
, 	 O
in 	 O
which 	 O
the 	 O
above 	 O
unrealistic 	 O
assumption 	 O
is 	 O
no 	 O
longer 	 O
necessary 	 O
. 	 O
The 	 O
proposed 	 O
method 	 O
can 	 O
defend 	 O
against 	 O
not 	 O
only 	 O
word 	 B
substitution 	 I
- 	 O
based 	 O
attacks 	 O
, 	 O
but 	 O
also 	 O
character 	 B
- 	 I
level 	 I
perturbations 	 O
. 	 O
We 	 O
can 	 O
certify 	 B
the 	 O
classifications 	 B
of 	 O
over 	 O
50 	 O
% 	 O
of 	 O
texts 	 O
to 	 O
be 	 O
robust 	 B
to 	 O
any 	 O
perturbation 	 O
of 	 O
five 	 O
words 	 O
on 	 O
AGNEWS 	 B
, 	 O
and 	 O
two 	 O
words 	 O
on 	 O
SST2 	 B
dataset 	 O
. 	 O
The 	 O
experimental 	 O
results 	 O
show 	 O
that 	 O
our 	 O
randomized 	 O
smoothing 	 B
method 	 O
significantly 	 O
outperforms 	 O
recently 	 O
proposed 	 O
defense 	 O
methods 	 O
across 	 O
multiple 	 O
datasets 	 O
under 	 O
different 	 O
attack 	 O
algorithms 	 O
. 	 O
