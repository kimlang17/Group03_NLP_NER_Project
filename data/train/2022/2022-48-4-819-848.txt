To	O
achieve	O
lifelong	O
language	B
learning	O
,	O
pseudo-rehearsal	B
methods	O
leverage	O
samples	O
generated	O
from	O
a	O
language	B
model	I
to	O
refresh	O
the	O
knowledge	O
of	O
previously	O
learned	O
tasks	O
.	O
Without	O
proper	O
controls	O
,	O
however	O
,	O
these	O
methods	O
could	O
fail	O
to	O
retain	O
the	O
knowledge	O
of	O
complex	O
tasks	O
with	O
longer	O
texts	O
since	O
most	O
of	O
the	O
generated	O
samples	O
are	O
low	O
in	O
quality	O
.	O
To	O
overcome	O
the	O
problem	O
,	O
we	O
propose	O
three	O
specific	O
contributions	O
.	O
First	O
,	O
we	O
utilize	O
double	B
language	I
models	I
,	O
each	O
of	O
which	O
specializes	O
in	O
a	O
specific	O
part	O
of	O
the	O
input	O
,	O
to	O
produce	O
high-quality	O
pseudo	B
samples	I
.	O
Second	O
,	O
we	O
reduce	O
the	O
number	O
of	O
parameters	O
used	O
by	O
applying	O
adapter	O
modules	O
to	O
enhance	O
training	O
efficiency	O
.	O
Third	O
,	O
we	O
further	O
improve	O
the	O
overall	O
quality	O
of	O
pseudo	B
samples	I
using	O
temporal	B
ensembling	I
and	O
sample	B
regeneration	I
.	O
The	O
results	O
show	O
that	O
our	O
framework	O
achieves	O
significant	O
improvement	O
over	O
baselines	O
on	O
multiple	O
task	O
sequences	O
.	O
Also	O
,	O
our	O
pseudo	B
sample	I
analysis	O
reveals	O
helpful	O
insights	O
for	O
designing	O
even	O
better	O
pseudo-rehearsal	B
methods	O
in	O
the	O
future	O
.	O
