Query	B
language	I
identification	I
(   O	O
Q   B
-   I
LID I
)	O
plays	O
a	O
crucial	O
role	O
in	O
a	O
cross   B
-   I
lingual	I
search	O
engine	O
.	O
There	O
exist	O
two	O
main	O
challenges	O
in	O
Q    B
-   I
LID	I
:	O
(   O	O
1	O
)	O
insufficient	O
contextual	O
information	O
in	O
queries	O
for	O
disambiguation	B
;	O
and	O
(   O	O
2	O
)	O
the	O
lack	O
of	O
query   O
-   O
style	O
training	O
examples	O
for	O
low    B
-   I
resource	I
languages	I
.	O
In	O
this	O
article	O
,	O
we	O
propose	O
a	O
neural	O
Q    B
-   I
LID	I
model	O
by	O
alleviating	O
the	O
above	O
problems	O
from	O
both	O
model	O
architecture	O
and	O
data	B
augmentation	I
perspectives	O
.	O
Concretely	O
,	O
we	O
build	O
our	O
model	O
upon	O
the	O
advanced	O
Transformer	B
model	I
.	O
In	O
order	O
to	O
enhance	O
the	O
discrimination	O
of	O
queries	O
,	O
a	O
variety	O
of	O
external	O
features	O
(   O	O
e.g.	O
,	O
character	O
,	O
word	O
,	O
as	O
well	O
as	O
script	O
)	O
are	O
fed	O
into	O
the	O
model	O
and	O
fused	O
by	O
a	O
multi-scale	B
attention	I
mechanism	I
.	O
Moreover	O
,	O
to	O
remedy	O
the	O
low	O
resource	B
challenge	I
in	O
this	O
task	O
,	O
a	O
novel	O
machine	O
translationâ€“based	B
strategy	I
is	O
proposed	O
to	O
automatically	O
generate	O
synthetic	O
query-style	O
data	O
for	O
low-resource	B
languages	I
.	O
We	O
contribute	O
the	O
first	O
Q-LID	B
test	I
set	I
called	O
QID-21	B
,	O
which	O
consists	O
of	O
search	O
queries	O
in	O
21	O
languages	O
.	O
Experimental	O
results	O
reveal	O
that	O
our	O
model	B
yields	I
better	O
classification	B
accuracy	I
than	O
strong	O
baselines	O
and	O
existing	O
LID	B
systems	I
on	O
both	O
query	O
and	O
traditional	B
LID	I
tasks   I	
.   O	O
1	O
