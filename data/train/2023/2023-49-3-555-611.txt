This	O
study	O
discusses	O
the	O
effect	O
of	O
semi-supervised	O
learning	O
in	O
combination	O
with	O
pretrained	O
language	B
models	I
for	O
data-to-text	O
generation	O
.	O
It	O
is	O
not	O
known	O
whether	O
semi-supervised	O
learning	O
is	O
still	O
helpful	O
when	O
a	O
large-scale	O
language	B
model	I
is	O
also	O
supplemented	O
.	O
This	O
study	O
aims	O
to	O
answer	O
this	O
question	O
by	O
comparing	O
a	O
data-to-text	O
system	O
only	O
supplemented	O
with	O
a	O
language	B
model	I
,	O
to	O
two	O
data-to-text	O
systems	O
that	O
are	O
additionally	O
enriched	O
by	O
a	O
data	O
augmentation	O
or	O
a	O
pseudo-labeling	O
semi-supervised	O
learning	O
approach	O
.	O
Results	O
show	O
that	O
semi-supervised	O
learning	O
results	O
in	O
higher	O
scores	O
on	O
diversity	O
metrics	O
.	O
In	O
terms	O
of	O
output	O
quality	O
,	O
extending	O
the	O
training	O
set	O
of	O
a	O
data-to-text	O
system	O
with	O
a	O
language	B
model	I
using	O
the	O
pseudo-labeling	O
approach	O
did	O
increase	O
text	O
quality	O
scores	O
,	O
but	O
the	O
data	O
augmentation	O
approach	O
yielded	O
similar	O
scores	O
to	O
the	O
system	O
without	O
training	O
set	O
extension	O
.	O
These	O
results	O
indicate	O
that	O
semi-supervised	O
learning	O
approaches	O
can	O
bolster	O
output	O
quality	O
and	O
diversity	O
,	O
even	O
when	O
a	O
language	B
model	I
is	O
also	O
present	O
.	O
