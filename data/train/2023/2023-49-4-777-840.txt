Large	O
neural	O
models	O
have	O
brought	O
a	O
new	O
challenge	O
to	O
natural	B
language	I
generation	I
(	O
NLG	O
)   O
:	O
It	O
has	O
become	O
imperative	O
to	O
ensure	O
the	O
safety	O
and	O
reliability	O
of	O
the	O
output	O
of	O
models	O
that	O
generate	O
freely	O
.	O
To	O
this	O
end	O
,	O
we	O
present	O
an	O
evaluation	O
framework	O
,	O
Attributable	O
to	O
Identified	O
Sources	O
(	O
AIS	O
)	O
,	O
stipulating	O
that	O
NLG	B
output	O
pertaining	O
to	O
the	O
external	O
world	O
is	O
to	O
be	O
verified	O
against	O
an	O
independent	O
,	O
provided	O
source	O
.	O
We	O
define	O
AIS	O
and	O
a	O
two-stage	O
annotation	O
pipeline	O
for	O
allowing	O
annotators	O
to	O
evaluate	O
model	O
output	O
according	O
to	O
annotation	O
guidelines	O
.	O
We	O
successfully	O
validate	O
this	O
approach	O
on	O
generation	O
datasets	O
spanning	O
three	O
tasks	O
(	O
two	O
conversational	O
QA	B
datasets	O
,	O
a	O
summarization	B
dataset	O
,	O
and	O
a	O
table-to-text	B
dataset	O
)	O
.	O
We	O
provide	O
full	O
annotation	O
guidelines	O
in	O
the	O
appendices	O
and	O
publicly	O
release	O
the	O
annotated	O
data	O
at	O
https	O
:	O
//github.com/google-research-datasets/AIS	O
.	O
