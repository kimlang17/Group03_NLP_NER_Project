The	O
utilization	O
of	O
monolingual	B
data	I
has	O
been	O
shown	O
to	O
be	O
a	O
promising	O
strategy	O
for	O
addressing	O
low-resource	O
machine	B
translation	I
problems	O
.	O
Previous	O
studies	O
have	O
demonstrated	O
the	O
effectiveness	O
of	O
techniques	O
such	O
as	O
back-translation	B
and	O
self-supervised	O
objectives	O
,	O
including	O
masked	B
language	I
modeling	I
,	O
causal	B
language	I
modeling	I
,	O
and	O
denoise	B
autoencoding	I
,	O
in	O
improving	O
the	O
performance	O
of	O
machine	B
translation	I
models	I
.	O
However	O
,	O
the	O
manner	O
in	O
which	O
these	O
methods	O
contribute	O
to	O
the	O
success	O
of	O
machine	B
translation	I
tasks	O
and	O
how	O
they	O
can	O
be	O
effectively	O
combined	O
remains	O
an	O
under-researched	O
area	O
.	O
In	O
this	O
study	O
,	O
we	O
carry	O
out	O
a	O
systematic	O
investigation	O
of	O
the	O
effects	O
of	O
these	O
techniques	O
on	O
linguistic	B
properties	I
through	O
the	O
use	O
of	O
probing	O
tasks	O
,	O
including	O
source	O
language	B
comprehension	I
,	O
bilingual	B
word	I
alignment	I
,	O
and	O
translation	B
fluency	I
.	O
We	O
further	O
evaluate	O
the	O
impact	O
of	O
pre-training	B
,	O
back-translation	B
,	O
and	O
multi-task	B
learning	I
on	O
bitexts	B
of	O
varying	O
sizes	O
.	O
Our	O
findings	O
inform	O
the	O
design	O
of	O
more	O
effective	O
pipelines	B
for	O
leveraging	B
monolingual	I
data	I
in	O
extremely	B
low-resource	I
and	O
low-resource	B
machine	I
translation	I
tasks	I
.	O
Experiment	O
results	O
show	O
consistent	O
performance	B
gains	O
in	O
seven	O
translation	B
directions	I
,	O
which	O
provide	O
further	O
support	O
for	O
our	O
conclusions	O
and	O
understanding	O
of	O
the	O
role	O
of	O
monolingual	B
data	I
in	O
machine	B
translation	I
.	O